
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorials/tutorial_image_container_zstacks.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/theislab/squidpy_notebooks/master?filepath=docs/source/auto_tutorials/tutorial_image_container_zstacks.ipynb
      :alt: Launch binder
      :width: 150 px

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_tutorial_image_container_zstacks.py:

Use z-stacks with ImageContainer
================================
In this example we showcase how to use z-stacks with :class:`squidpy.im.ImageContainer`

It is possible to acquire several consecutive image slices from the same tissue.
Squidpy's `ImageContainer` supports storing, processing, and visualization of these z-stacks.

Here, we use the Visium 10x mouse brain sagittal slices as an example of a z-stack image with two Z dimensions.
We will use the "hires" images contained in the :class:`anndata.AnnData` object, but you could also use the
original resolution tiff images in the `ImageContainer`.

.. seealso::

    See :ref:`sphx_glr_auto_tutorials_tutorial_image_container.py` for a general introduction to the `ImageContainer`.

Import Libraries and load individual image sections
---------------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 20-44

.. code-block:: default


    import scanpy as sc
    import anndata as ad
    import squidpy as sq

    library_ids = ["V1_Mouse_Brain_Sagittal_Posterior", "V1_Mouse_Brain_Sagittal_Posterior_Section_2"]

    adatas, imgs = [], []
    use_hires_tiff = False
    for library_id in library_ids:
        adatas.append(sc.datasets.visium_sge(library_id, include_hires_tiff=use_hires_tiff))
        adatas[-1].var_names_make_unique()
        if use_hires_tiff:
            imgs.append(sq.im.ImageContainer(adatas[-1].uns["spatial"][library_id]["metadata"]["source_image_path"]))
        else:
            # as we are using a scaled image, we need to specify a scalefactor
            # to allow correct mapping to adata.obsm['spatial']
            imgs.append(
                sq.im.ImageContainer(
                    adatas[-1].uns["spatial"][library_id]["images"]["hires"],
                    scale=adatas[-1].uns["spatial"][library_id]["scalefactors"]["tissue_hires_scalef"],
                )
            )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|          | 0.00/9.26M [00:00<?, ?B/s]      5%|5         | 520k/9.26M [00:00<00:01, 5.24MB/s]     13%|#3        | 1.21M/9.26M [00:00<00:01, 6.43MB/s]     21%|##        | 1.90M/9.26M [00:00<00:01, 6.76MB/s]     28%|##8       | 2.59M/9.26M [00:00<00:01, 6.97MB/s]     35%|###5      | 3.27M/9.26M [00:00<00:00, 7.01MB/s]     42%|####2     | 3.90M/9.26M [00:00<00:00, 6.83MB/s]     50%|####9     | 4.60M/9.26M [00:00<00:00, 6.95MB/s]     57%|#####7    | 5.30M/9.26M [00:00<00:00, 7.07MB/s]     65%|######4   | 6.01M/9.26M [00:00<00:00, 7.12MB/s]     72%|#######2  | 6.71M/9.26M [00:01<00:00, 7.16MB/s]     80%|########  | 7.41M/9.26M [00:01<00:00, 7.18MB/s]     88%|########7 | 8.12M/9.26M [00:01<00:00, 7.19MB/s]     95%|#########5| 8.82M/9.26M [00:01<00:00, 7.19MB/s]    100%|##########| 9.26M/9.26M [00:01<00:00, 7.02MB/s]
      0%|          | 0.00/20.1M [00:00<?, ?B/s]      0%|          | 16.0k/20.1M [00:00<04:23, 80.0kB/s]      0%|          | 96.0k/20.1M [00:00<01:40, 208kB/s]       2%|2         | 416k/20.1M [00:00<00:25, 822kB/s]       4%|4         | 880k/20.1M [00:00<00:12, 1.59MB/s]      8%|7         | 1.55M/20.1M [00:00<00:06, 2.91MB/s]     11%|#         | 2.12M/20.1M [00:01<00:05, 3.66MB/s]     14%|#4        | 2.83M/20.1M [00:01<00:03, 4.60MB/s]     18%|#7        | 3.53M/20.1M [00:01<00:03, 5.33MB/s]     21%|##        | 4.22M/20.1M [00:01<00:02, 5.85MB/s]     24%|##4       | 4.92M/20.1M [00:01<00:02, 6.25MB/s]     28%|##7       | 5.59M/20.1M [00:01<00:02, 6.47MB/s]     31%|###1      | 6.28M/20.1M [00:01<00:02, 6.68MB/s]     35%|###4      | 6.97M/20.1M [00:01<00:02, 6.83MB/s]     38%|###8      | 7.67M/20.1M [00:01<00:01, 6.95MB/s]     41%|####1     | 8.27M/20.1M [00:01<00:01, 6.72MB/s]     45%|####4     | 8.95M/20.1M [00:02<00:01, 6.85MB/s]     48%|####8     | 9.66M/20.1M [00:02<00:01, 6.96MB/s]     52%|#####1    | 10.4M/20.1M [00:02<00:01, 7.05MB/s]     55%|#####4    | 11.0M/20.1M [00:02<00:01, 6.78MB/s]     59%|#####8    | 11.8M/20.1M [00:02<00:01, 7.24MB/s]     62%|######2   | 12.5M/20.1M [00:02<00:01, 7.24MB/s]     66%|######5   | 13.2M/20.1M [00:02<00:00, 7.23MB/s]     69%|######9   | 14.0M/20.1M [00:02<00:00, 7.24MB/s]     73%|#######2  | 14.7M/20.1M [00:02<00:00, 7.24MB/s]     76%|#######6  | 15.3M/20.1M [00:02<00:00, 7.23MB/s]     80%|#######9  | 16.0M/20.1M [00:03<00:00, 7.24MB/s]     83%|########3 | 16.7M/20.1M [00:03<00:00, 7.23MB/s]     87%|########6 | 17.4M/20.1M [00:03<00:00, 7.21MB/s]     90%|######### | 18.1M/20.1M [00:03<00:00, 7.16MB/s]     94%|#########3| 18.8M/20.1M [00:03<00:00, 7.18MB/s]     97%|#########7| 19.5M/20.1M [00:03<00:00, 7.19MB/s]    100%|##########| 20.1M/20.1M [00:03<00:00, 5.78MB/s]
      0%|          | 0.00/9.26M [00:00<?, ?B/s]      0%|          | 32.0k/9.26M [00:00<01:29, 108kB/s]      2%|2         | 200k/9.26M [00:00<00:18, 511kB/s]       4%|4         | 416k/9.26M [00:00<00:10, 890kB/s]      9%|9         | 880k/9.26M [00:00<00:05, 1.73MB/s]     17%|#6        | 1.56M/9.26M [00:00<00:02, 3.15MB/s]     23%|##2       | 2.12M/9.26M [00:00<00:01, 3.87MB/s]     31%|###       | 2.83M/9.26M [00:01<00:01, 4.82MB/s]     38%|###7      | 3.52M/9.26M [00:01<00:01, 5.47MB/s]     46%|####5     | 4.22M/9.26M [00:01<00:00, 5.99MB/s]     53%|#####3    | 4.92M/9.26M [00:01<00:00, 6.37MB/s]     61%|######    | 5.62M/9.26M [00:01<00:00, 6.62MB/s]     68%|######8   | 6.32M/9.26M [00:01<00:00, 6.82MB/s]     76%|#######5  | 7.02M/9.26M [00:01<00:00, 6.92MB/s]     83%|########3 | 7.72M/9.26M [00:01<00:00, 7.01MB/s]     91%|######### | 8.41M/9.26M [00:01<00:00, 7.09MB/s]     98%|#########8| 9.11M/9.26M [00:01<00:00, 7.12MB/s]    100%|##########| 9.26M/9.26M [00:01<00:00, 4.89MB/s]
      0%|          | 0.00/19.0M [00:00<?, ?B/s]      2%|2         | 416k/19.0M [00:00<00:05, 3.35MB/s]      6%|5         | 1.11M/19.0M [00:00<00:03, 5.45MB/s]     10%|9         | 1.80M/19.0M [00:00<00:02, 6.23MB/s]     13%|#3        | 2.49M/19.0M [00:00<00:02, 6.60MB/s]     17%|#6        | 3.20M/19.0M [00:00<00:02, 6.84MB/s]     20%|##        | 3.89M/19.0M [00:00<00:02, 6.99MB/s]     24%|##4       | 4.59M/19.0M [00:00<00:02, 7.04MB/s]     28%|##7       | 5.29M/19.0M [00:00<00:02, 7.09MB/s]     31%|###1      | 5.98M/19.0M [00:00<00:01, 7.12MB/s]     35%|###5      | 6.66M/19.0M [00:01<00:01, 7.14MB/s]     39%|###8      | 7.37M/19.0M [00:01<00:01, 7.17MB/s]     42%|####2     | 8.04M/19.0M [00:01<00:01, 7.12MB/s]     46%|####5     | 8.73M/19.0M [00:01<00:01, 7.10MB/s]     50%|####9     | 9.43M/19.0M [00:01<00:01, 7.13MB/s]     53%|#####3    | 10.1M/19.0M [00:01<00:01, 7.00MB/s]     57%|#####6    | 10.8M/19.0M [00:01<00:01, 7.06MB/s]     60%|######    | 11.5M/19.0M [00:01<00:01, 7.11MB/s]     64%|######4   | 12.2M/19.0M [00:01<00:00, 7.15MB/s]     68%|######7   | 12.9M/19.0M [00:01<00:00, 7.17MB/s]     72%|#######1  | 13.6M/19.0M [00:02<00:00, 7.20MB/s]     75%|#######5  | 14.3M/19.0M [00:02<00:00, 7.19MB/s]     79%|#######8  | 15.0M/19.0M [00:02<00:00, 7.22MB/s]     83%|########2 | 15.7M/19.0M [00:02<00:00, 7.23MB/s]     86%|########6 | 16.4M/19.0M [00:02<00:00, 7.21MB/s]     90%|######### | 17.1M/19.0M [00:02<00:00, 7.24MB/s]     94%|#########3| 17.8M/19.0M [00:02<00:00, 7.24MB/s]     97%|#########7| 18.5M/19.0M [00:02<00:00, 7.20MB/s]    100%|##########| 19.0M/19.0M [00:02<00:00, 7.02MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 45-58

Concatenate per-section data to a z-stack
-----------------------------------------
To allow mapping from observations in `adata` to the correct Z dimension in `img`,
we will store a ``library_id`` column in ``adata.obs`` and associate each ``library_id``
to a Z dimension in the `ImageContainer`.

For this, we will use :func:`anndata.concat` with ``uns_merge = only``
(to ensure that `uns` entries are correctly concatenated),
``label = 'library_id'`` and ``keys = library_ids`` (to create the necessary column in ``adata.obs``.

To concatenate the individual :class:`squidpy.im.ImageContainer`,
we will use :meth:`squidpy.im.ImageContainer.concat`, specifying
``library_ids = library_ids`` for associating each image with the correct observations in `adata`.

.. GENERATED FROM PYTHON SOURCE LINES 58-61

.. code-block:: default

    adata = ad.concat(adatas, uns_merge="only", label="library_id", keys=library_ids, index_unique="-")
    img = sq.im.ImageContainer.concat(imgs, library_ids=library_ids)








.. GENERATED FROM PYTHON SOURCE LINES 62-63

`adata` now contains a ``library_id`` column in ``adata.obs``, which maps observations to a unique `library_id`.

.. GENERATED FROM PYTHON SOURCE LINES 63-66

.. code-block:: default

    print(adata)
    adata.obs





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    AnnData object with n_obs × n_vars = 6644 × 32285
        obs: 'in_tissue', 'array_row', 'array_col', 'library_id'
        uns: 'spatial'
        obsm: 'spatial'


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>in_tissue</th>
          <th>array_row</th>
          <th>array_col</th>
          <th>library_id</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>AAACAAGTATCTCCCA-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>1</td>
          <td>50</td>
          <td>102</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior</td>
        </tr>
        <tr>
          <th>AAACACCAATAACTGC-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>1</td>
          <td>59</td>
          <td>19</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior</td>
        </tr>
        <tr>
          <th>AAACAGAGCGACTCCT-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>1</td>
          <td>14</td>
          <td>94</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior</td>
        </tr>
        <tr>
          <th>AAACAGCTTTCAGAAG-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>1</td>
          <td>43</td>
          <td>9</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior</td>
        </tr>
        <tr>
          <th>AAACAGGGTCTATATT-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>1</td>
          <td>47</td>
          <td>13</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>TTGTTGTGTGTCAAGA-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>1</td>
          <td>31</td>
          <td>77</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior_Section_2</td>
        </tr>
        <tr>
          <th>TTGTTTCACATCCAGG-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>1</td>
          <td>58</td>
          <td>42</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior_Section_2</td>
        </tr>
        <tr>
          <th>TTGTTTCATTAGTCTA-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>1</td>
          <td>60</td>
          <td>30</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior_Section_2</td>
        </tr>
        <tr>
          <th>TTGTTTCCATACAACT-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>1</td>
          <td>45</td>
          <td>27</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior_Section_2</td>
        </tr>
        <tr>
          <th>TTGTTTGTATTACACG-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>1</td>
          <td>73</td>
          <td>41</td>
          <td>V1_Mouse_Brain_Sagittal_Posterior_Section_2</td>
        </tr>
      </tbody>
    </table>
    <p>6644 rows × 4 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 67-69

`img` contains the 2D images concatenated along the Z dimension in one image layer.
The Z dimensions are named the same as the `library_id`'s in `adata` to allow a mapping from `adata` to `img`.

.. GENERATED FROM PYTHON SOURCE LINES 69-72

.. code-block:: default

    print(img["image"].z)
    img





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <xarray.DataArray 'z' (z: 2)>
    array(['V1_Mouse_Brain_Sagittal_Posterior',
           'V1_Mouse_Brain_Sagittal_Posterior_Section_2'], dtype='<U43')
    Coordinates:
      * z        (z) <U43 'V1_Mouse_Brain_Sagittal_Posterior' 'V1_Mouse_Brain_Sag...


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    ImageContainer object with 1 layer:<p style='text-indent: 25px; margin-top: 0px; margin-bottom: 0px;'><strong>image</strong>: <em>y</em> (1998), <em>x</em> (2000), <em>z</em> (2), <em>channels</em> (3)</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 73-76

It is also possible to initialize the `ImageContainer` with images that already contain the Z dimension.
In this case you need to specify the ``library_id`` argument in the constructor.
In addition, you might want to set ``dims`` to the correct ordering of dimensions manually for more control.

.. GENERATED FROM PYTHON SOURCE LINES 76-81

.. code-block:: default

    arr = img["image"].values
    print(arr.shape)
    img2 = sq.im.ImageContainer(arr, library_id=library_ids, dims=("y", "x", "z", "channels"))
    img2





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (1998, 2000, 2, 3)


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    ImageContainer object with 1 layer:<p style='text-indent: 25px; margin-top: 0px; margin-bottom: 0px;'><strong>image</strong>: <em>y</em> (1998), <em>x</em> (2000), <em>z</em> (2), <em>channels</em> (3)</p>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 82-86

Generally, an `ImageContainer` with more than one Z dimension can be used in the same way as an `ImageContainer`
with only one Z dimension.
In addition, we can specify `library_id` to cropping, pre-processing,
and segmentation functions if we'd like to only process a specific `library_id`.

.. GENERATED FROM PYTHON SOURCE LINES 88-91

Visualization
-------------
For using :func:`scanpy.pl.spatial`, subset the `adata` to the desired `library_id`.

.. GENERATED FROM PYTHON SOURCE LINES 91-94

.. code-block:: default

    library_id = library_ids[0]
    sc.pl.spatial(adata[adata.obs["library_id"] == library_id], library_id=library_id, color="in_tissue")




.. image:: /auto_tutorials/images/sphx_glr_tutorial_image_container_zstacks_001.png
    :alt: in_tissue
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 95-97

:meth:`squidpy.im.ImageContainer.show` works with z-stacks out of the box, by plotting them as separate images.
Additionally, you can specify a `library_id` if you only want to plot one Z dimension.

.. GENERATED FROM PYTHON SOURCE LINES 97-99

.. code-block:: default

    img.show()




.. image:: /auto_tutorials/images/sphx_glr_tutorial_image_container_zstacks_002.png
    :alt: image, library_id:V1_Mouse_Brain_Sagittal_Posterior, image, library_id:V1_Mouse_Brain_Sagittal_Posterior_Section_2
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 100-110

Interactive visualization of z-stacks is also possible.
The Napari viewer will have a slider at the bottom, allowing you to choose the Z dimension to display.
The `adata` observations are automatically updated to the current Z dimension.

When calling ``img.interactive`` just specify ``library_key`` as the column name in ``adata.obs``
which maps from observations to `library_ids`

.. code-block:: python

   img.interactive(adata, library_key='library_id')

.. GENERATED FROM PYTHON SOURCE LINES 112-115

Cropping
--------
By default, the cropping functions will crop all Z dimensions.

.. GENERATED FROM PYTHON SOURCE LINES 115-118

.. code-block:: default

    crop = img.crop_corner(500, 1000, size=500)
    crop.show()




.. image:: /auto_tutorials/images/sphx_glr_tutorial_image_container_zstacks_003.png
    :alt: image, library_id:V1_Mouse_Brain_Sagittal_Posterior, image, library_id:V1_Mouse_Brain_Sagittal_Posterior_Section_2
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 119-120

You can also specify ``library_id``, as either a single or multiple Z dimensions to crop.

.. GENERATED FROM PYTHON SOURCE LINES 120-123

.. code-block:: default


    img.crop_corner(500, 1000, size=500, library_id=library_ids[0]).show()




.. image:: /auto_tutorials/images/sphx_glr_tutorial_image_container_zstacks_004.png
    :alt: image
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 124-131

Processing and segmenting
-------------------------
Let us smooth the image.
When not specifying a `library_id`, :func:`squidpy.im.process` treats the image as a 3D volume.
As we would like to smooth only in x and y dimensions, and not in z, we need so specify a per-dimension `sigma`.
The internal dimensions of the image are ``y, x, z, channels``, as you can check with ``crop['image'].dims``.
Therefore, to only smooth in x and y, we need to specify ``sigma = [10, 10, 0, 0]``.

.. GENERATED FROM PYTHON SOURCE LINES 131-134

.. code-block:: default

    sq.im.process(img, layer="image", method="smooth", sigma=[10, 10, 0, 0], layer_added="smooth1")
    img.show("smooth1")




.. image:: /auto_tutorials/images/sphx_glr_tutorial_image_container_zstacks_005.png
    :alt: smooth1, library_id:V1_Mouse_Brain_Sagittal_Posterior, smooth1, library_id:V1_Mouse_Brain_Sagittal_Posterior_Section_2
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 135-141

Now, let us just smooth one `library_id`.
Specifying `library_id` means that the processing function will process each Z dimension separately.
This means that now the dimensions of the processed image are ``y, x, channels`` (with ``z`` removed), meaning that
we have to update `sigma` accordingly.
If the number of channels does not change due to the processing, :func:`squidpy.im.process` implies the identity
function for non-processed Z dimensions.

.. GENERATED FROM PYTHON SOURCE LINES 141-144

.. code-block:: default

    sq.im.process(img, layer="image", method="smooth", sigma=10, layer_added="smooth2", library_id=library_ids[0])
    img.show("smooth2")




.. image:: /auto_tutorials/images/sphx_glr_tutorial_image_container_zstacks_006.png
    :alt: smooth2, library_id:V1_Mouse_Brain_Sagittal_Posterior, smooth2, library_id:V1_Mouse_Brain_Sagittal_Posterior_Section_2
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 145-150

None, only the first `library_id` is smoothed.
For the second, the original image was used.

If the processing function changes the number of dimensions, non-processed Z dimensions will contain 0.
Let's see this behavior with using ``method = 'gray'``, which moves from 3 channels (RGB) to one channel (gray).

.. GENERATED FROM PYTHON SOURCE LINES 150-153

.. code-block:: default

    sq.im.process(img, layer="image", method="gray", layer_added="gray", library_id=library_ids[0])
    img.show("gray", cmap="gray")




.. image:: /auto_tutorials/images/sphx_glr_tutorial_image_container_zstacks_007.png
    :alt: gray, library_id:V1_Mouse_Brain_Sagittal_Posterior, gray, library_id:V1_Mouse_Brain_Sagittal_Posterior_Section_2
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 154-167

:func:`squidpy.im.segment` works in the same way, just specify `library_id` if you only wish to
segment specific Z dimensions.

Feature calculation
-------------------
Calculating features from z-stack images is straight forward as well.
With more than one Z dimension, we just need to specify the column name in ``adata.obs``
which contains the mapping from observations to `library_ids`
to allow the function to extract the features from the correct Z dimension.
As of now, features can only be extracted on 2D, meaning from the Z dimension that the current spot is located on.

The following call extracts features for each observation in `adata`, automatically choosing the correct
Z dimension in `img`.

.. GENERATED FROM PYTHON SOURCE LINES 167-171

.. code-block:: default

    adata_crop = crop.subset(adata)  # subset adata to the image crop
    sq.im.calculate_image_features(adata_crop, crop, library_id="library_id", layer="image", features="summary", n_jobs=4)
    adata_crop.obsm["img_features"]





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|          | 0/774 [00:00<?, ?/s]


.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>summary_ch-0_quantile-0.9</th>
          <th>summary_ch-0_quantile-0.5</th>
          <th>summary_ch-0_quantile-0.1</th>
          <th>summary_ch-0_mean</th>
          <th>summary_ch-0_std</th>
          <th>summary_ch-1_quantile-0.9</th>
          <th>summary_ch-1_quantile-0.5</th>
          <th>summary_ch-1_quantile-0.1</th>
          <th>summary_ch-1_mean</th>
          <th>summary_ch-1_std</th>
          <th>summary_ch-2_quantile-0.9</th>
          <th>summary_ch-2_quantile-0.5</th>
          <th>summary_ch-2_quantile-0.1</th>
          <th>summary_ch-2_mean</th>
          <th>summary_ch-2_std</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>AAACAGAGCGACTCCT-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>0.721569</td>
          <td>0.670588</td>
          <td>0.542745</td>
          <td>0.647495</td>
          <td>0.074835</td>
          <td>0.725490</td>
          <td>0.611765</td>
          <td>0.247059</td>
          <td>0.517943</td>
          <td>0.209248</td>
          <td>0.729412</td>
          <td>0.674510</td>
          <td>0.549020</td>
          <td>0.652933</td>
          <td>0.074534</td>
        </tr>
        <tr>
          <th>AAACGAGACGGTTGAT-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>0.450980</td>
          <td>0.309804</td>
          <td>0.200000</td>
          <td>0.317769</td>
          <td>0.095004</td>
          <td>0.360784</td>
          <td>0.270588</td>
          <td>0.184314</td>
          <td>0.269996</td>
          <td>0.069024</td>
          <td>0.576471</td>
          <td>0.509804</td>
          <td>0.462745</td>
          <td>0.515190</td>
          <td>0.045777</td>
        </tr>
        <tr>
          <th>AAATTACCTATCGATG-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>0.680784</td>
          <td>0.611765</td>
          <td>0.487843</td>
          <td>0.599930</td>
          <td>0.075161</td>
          <td>0.517647</td>
          <td>0.462745</td>
          <td>0.379608</td>
          <td>0.455529</td>
          <td>0.055273</td>
          <td>0.692549</td>
          <td>0.650980</td>
          <td>0.596078</td>
          <td>0.647303</td>
          <td>0.041485</td>
        </tr>
        <tr>
          <th>AACAGGAAATCGAATA-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>0.658824</td>
          <td>0.603922</td>
          <td>0.511373</td>
          <td>0.594231</td>
          <td>0.057229</td>
          <td>0.521569</td>
          <td>0.466667</td>
          <td>0.393725</td>
          <td>0.462379</td>
          <td>0.048675</td>
          <td>0.678431</td>
          <td>0.643137</td>
          <td>0.584314</td>
          <td>0.635939</td>
          <td>0.035439</td>
        </tr>
        <tr>
          <th>AACATATCAACTGGTG-1-V1_Mouse_Brain_Sagittal_Posterior</th>
          <td>0.586667</td>
          <td>0.360784</td>
          <td>0.211765</td>
          <td>0.385795</td>
          <td>0.140289</td>
          <td>0.447059</td>
          <td>0.301961</td>
          <td>0.185882</td>
          <td>0.308392</td>
          <td>0.098326</td>
          <td>0.645490</td>
          <td>0.533333</td>
          <td>0.444706</td>
          <td>0.540601</td>
          <td>0.071795</td>
        </tr>
        <tr>
          <th>...</th>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
          <td>...</td>
        </tr>
        <tr>
          <th>TTGGGACACTGCCCGC-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>0.635294</td>
          <td>0.580392</td>
          <td>0.480000</td>
          <td>0.564357</td>
          <td>0.063804</td>
          <td>0.522353</td>
          <td>0.466667</td>
          <td>0.397647</td>
          <td>0.464401</td>
          <td>0.049290</td>
          <td>0.674510</td>
          <td>0.631373</td>
          <td>0.580392</td>
          <td>0.627468</td>
          <td>0.038752</td>
        </tr>
        <tr>
          <th>TTGGGCGGCGGTTGCC-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>0.643137</td>
          <td>0.592157</td>
          <td>0.502745</td>
          <td>0.582867</td>
          <td>0.055017</td>
          <td>0.556863</td>
          <td>0.505882</td>
          <td>0.435294</td>
          <td>0.500200</td>
          <td>0.047835</td>
          <td>0.666667</td>
          <td>0.631373</td>
          <td>0.581961</td>
          <td>0.626580</td>
          <td>0.033794</td>
        </tr>
        <tr>
          <th>TTGTAAGGCCAGTTGG-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>0.670588</td>
          <td>0.627451</td>
          <td>0.537255</td>
          <td>0.615948</td>
          <td>0.055211</td>
          <td>0.602353</td>
          <td>0.556863</td>
          <td>0.483922</td>
          <td>0.548758</td>
          <td>0.047661</td>
          <td>0.694118</td>
          <td>0.662745</td>
          <td>0.596078</td>
          <td>0.652636</td>
          <td>0.036439</td>
        </tr>
        <tr>
          <th>TTGTTCAGTGTGCTAC-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>0.647059</td>
          <td>0.584314</td>
          <td>0.476078</td>
          <td>0.571329</td>
          <td>0.064511</td>
          <td>0.545098</td>
          <td>0.494118</td>
          <td>0.419608</td>
          <td>0.489499</td>
          <td>0.048448</td>
          <td>0.674510</td>
          <td>0.639216</td>
          <td>0.592157</td>
          <td>0.636148</td>
          <td>0.032888</td>
        </tr>
        <tr>
          <th>TTGTTGTGTGTCAAGA-1-V1_Mouse_Brain_Sagittal_Posterior_Section_2</th>
          <td>0.662745</td>
          <td>0.623529</td>
          <td>0.510588</td>
          <td>0.607930</td>
          <td>0.060086</td>
          <td>0.623529</td>
          <td>0.568627</td>
          <td>0.480000</td>
          <td>0.560070</td>
          <td>0.054016</td>
          <td>0.682353</td>
          <td>0.654902</td>
          <td>0.607843</td>
          <td>0.648872</td>
          <td>0.030845</td>
        </tr>
      </tbody>
    </table>
    <p>774 rows × 15 columns</p>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 172-176

The calculated features can now be used in downstream Scanpy analyses, by e.g. using all Z dimensions
to cluster spots based on image features and gene features.

Here, we cluster genes and calculated features using a standard Scanpy workflow.

.. GENERATED FROM PYTHON SOURCE LINES 176-185

.. code-block:: default

    sc.pp.normalize_total(adata_crop, inplace=True)
    sc.pp.log1p(adata_crop)
    sc.pp.pca(adata_crop)
    sc.pp.neighbors(adata_crop)
    sc.tl.leiden(adata_crop)

    sc.pp.neighbors(adata_crop, use_rep="img_features", key_added="neigh_features")
    sc.tl.leiden(adata_crop, neighbors_key="neigh_features", key_added="leiden_features")








.. GENERATED FROM PYTHON SOURCE LINES 186-191

Visualize the result interactively using Napari, or statically using :func:`scanpy.pl.spatial`:

.. code-block:: python

   img.interactive(adata, library_key='library_id')

.. GENERATED FROM PYTHON SOURCE LINES 191-202

.. code-block:: default

    sc.pl.spatial(
        adata_crop[adata_crop.obs["library_id"] == library_ids[0]],
        library_id=library_ids[0],
        color=["leiden", "leiden_features"],
    )

    sc.pl.spatial(
        adata_crop[adata_crop.obs["library_id"] == library_ids[1]],
        library_id=library_ids[1],
        color=["leiden", "leiden_features"],
    )



.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_tutorials/images/sphx_glr_tutorial_image_container_zstacks_008.png
          :alt: leiden, leiden_features
          :class: sphx-glr-multi-img

    *

      .. image:: /auto_tutorials/images/sphx_glr_tutorial_image_container_zstacks_009.png
          :alt: leiden, leiden_features
          :class: sphx-glr-multi-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  46.310 seconds)

**Estimated memory usage:**  1581 MB


.. _sphx_glr_download_auto_tutorials_tutorial_image_container_zstacks.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: tutorial_image_container_zstacks.py <tutorial_image_container_zstacks.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: tutorial_image_container_zstacks.ipynb <tutorial_image_container_zstacks.ipynb>`
