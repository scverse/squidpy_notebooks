{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use z-stacks with ImageContainer\n\nIn this example we showcase how to use z-stacks with\n`squidpy.im.ImageContainer`\n\nIt is possible to acquire several consecutive image slices from the same\ntissue. Squidpy\\'s [ImageContainer]{.title-ref} supports storing,\nprocessing, and visualization of these z-stacks.\n\nHere, we use the Visium 10x mouse brain sagittal slices as an example of\na z-stack image with two Z dimensions. We will use the \\\"hires\\\" images\ncontained in the `anndata.AnnData` object, but you could also use the\noriginal resolution tiff images in the [ImageContainer]{.title-ref}.\n\n::: seealso\nSee `sphx_glr_auto_tutorials_tutorial_image_container.py` for a general\nintroduction to the [ImageContainer]{.title-ref}.\n:::\n\n## Import libraries and load individual image sections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\nimport anndata as ad\nimport squidpy as sq\n\nlibrary_ids = [\"V1_Mouse_Brain_Sagittal_Posterior\", \"V1_Mouse_Brain_Sagittal_Posterior_Section_2\"]\n\nadatas, imgs = [], []\nuse_hires_tiff = False\nfor library_id in library_ids:\n    adatas.append(sc.datasets.visium_sge(library_id, include_hires_tiff=use_hires_tiff))\n    adatas[-1].var_names_make_unique()\n    if use_hires_tiff:\n        imgs.append(sq.im.ImageContainer(adatas[-1].uns[\"spatial\"][library_id][\"metadata\"][\"source_image_path\"]))\n    else:\n        # as we are using a scaled image, we need to specify a scalefactor\n        # to allow correct mapping to adata.obsm['spatial']\n        imgs.append(\n            sq.im.ImageContainer(\n                adatas[-1].uns[\"spatial\"][library_id][\"images\"][\"hires\"],\n                scale=adatas[-1].uns[\"spatial\"][library_id][\"scalefactors\"][\"tissue_hires_scalef\"],\n            )\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Concatenate per-section data to a z-stack\n\nTo allow mapping from observations in [adata]{.title-ref} to the correct\nZ dimension in [img]{.title-ref}, we will store a `library_id` column in\n`adata.obs` and associate each `library_id` to a Z dimension in the\n[ImageContainer]{.title-ref}.\n\nFor this, we will use `anndata.concat` with `uns_merge = only` (to\nensure that [uns]{.title-ref} entries are correctly concatenated),\n`label = 'library_id'` and `keys = library_ids` (to create the necessary\ncolumn in `adata.obs`.\n\nTo concatenate the individual `squidpy.im.ImageContainer`, we will use\n`squidpy.im.ImageContainer.concat`, specifying\n`library_ids = library_ids` for associating each image with the correct\nobservations in [adata]{.title-ref}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adata = ad.concat(adatas, uns_merge=\"only\", label=\"library_id\", keys=library_ids, index_unique=\"-\")\nimg = sq.im.ImageContainer.concat(imgs, library_ids=library_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[adata]{.title-ref} now contains a `library_id` column in `adata.obs`,\nwhich maps observations to a unique [library_id]{.title-ref}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(adata)\nadata.obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[img]{.title-ref} contains the 2D images concatenated along the Z\ndimension in one image layer. The Z dimensions are named the same as the\n[library_id]{.title-ref}\\'s in [adata]{.title-ref} to allow a mapping\nfrom [adata]{.title-ref} to [img]{.title-ref}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(img[\"image\"].z)\nimg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also possible to initialize the [ImageContainer]{.title-ref} with\nimages that already contain the Z dimension. In this case you need to\nspecify the `library_id` argument in the constructor. In addition, you\nmight want to set `dims` to the correct ordering of dimensions manually\nfor more control.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "arr = img[\"image\"].values\nprint(arr.shape)\nimg2 = sq.im.ImageContainer(arr, library_id=library_ids, dims=(\"y\", \"x\", \"z\", \"channels\"))\nimg2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generally, an [ImageContainer]{.title-ref} with more than one Z\ndimension can be used in the same way as an [ImageContainer]{.title-ref}\nwith only one Z dimension. In addition, we can specify\n[library_id]{.title-ref} to cropping, pre-processing, and segmentation\nfunctions if we\\'d like to only process a specific\n[library_id]{.title-ref}.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualization\n\nFor using `scanpy.pl.spatial`, subset the [adata]{.title-ref} to the\ndesired [library_id]{.title-ref}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "library_id = library_ids[0]\nsc.pl.spatial(adata[adata.obs[\"library_id\"] == library_id], library_id=library_id, color=\"in_tissue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`squidpy.im.ImageContainer.show` works with z-stacks out of the box, by\nplotting them as separate images. Additionally, you can specify a\n[library_id]{.title-ref} if you only want to plot one Z dimension.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interactive visualization of z-stacks is also possible. The Napari\nviewer will have a slider at the bottom, allowing you to choose the Z\ndimension to display. The [adata]{.title-ref} observations are\nautomatically updated to the current Z dimension.\n\nWhen calling `img.interactive` just specify `library_key` as the column\nname in `adata.obs` which maps from observations to\n[library_ids]{.title-ref}\n\n``` python\nimg.interactive(adata, library_key='library_id')\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cropping\n\nBy default, the cropping functions will crop all Z dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "crop = img.crop_corner(500, 1000, size=500)\ncrop.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also specify `library_id`, as either a single or multiple Z\ndimensions to crop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img.crop_corner(500, 1000, size=500, library_id=library_ids[0]).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Processing and segmenting\n\nLet us smooth the image. When not specifying a [library_id]{.title-ref},\n`squidpy.im.process` treats the image as a 3D volume. As we would like\nto smooth only in x and y dimensions, and not in z, we need so specify a\nper-dimension [sigma]{.title-ref}. The internal dimensions of the image\nare `y, x, z, channels`, as you can check with `crop['image'].dims`.\nTherefore, to only smooth in x and y, we need to specify\n`sigma = [10, 10, 0, 0]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.process(img, layer=\"image\", method=\"smooth\", sigma=[10, 10, 0, 0], layer_added=\"smooth1\")\nimg.show(\"smooth1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let us just smooth one [library_id]{.title-ref}. Specifying\n[library_id]{.title-ref} means that the processing function will process\neach Z dimension separately. This means that now the dimensions of the\nprocessed image are `y, x, channels` (with `z` removed), meaning that we\nhave to update [sigma]{.title-ref} accordingly. If the number of\nchannels does not change due to the processing, `squidpy.im.process`\nimplies the identity function for non-processed Z dimensions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.process(img, layer=\"image\", method=\"smooth\", sigma=10, layer_added=\"smooth2\", library_id=library_ids[0])\nimg.show(\"smooth2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "None, only the first [library_id]{.title-ref} is smoothed. For the\nsecond, the original image was used.\n\nIf the processing function changes the number of dimensions,\nnon-processed Z dimensions will contain 0. Let\\'s see this behavior with\nusing `method = 'gray'`, which moves from 3 channels (RGB) to one\nchannel (gray).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.process(img, layer=\"image\", method=\"gray\", layer_added=\"gray\", library_id=library_ids[0])\nimg.show(\"gray\", cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`squidpy.im.segment` works in the same way, just specify\n[library_id]{.title-ref} if you only wish to segment specific Z\ndimensions.\n\n# Feature calculation\n\nCalculating features from z-stack images is straight forward as well.\nWith more than one Z dimension, we just need to specify the column name\nin `adata.obs` which contains the mapping from observations to\n[library_ids]{.title-ref} to allow the function to extract the features\nfrom the correct Z dimension. As of now, features can only be extracted\non 2D, meaning from the Z dimension that the current spot is located on.\n\nThe following call extracts features for each observation in\n[adata]{.title-ref}, automatically choosing the correct Z dimension in\n[img]{.title-ref}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adata_crop = crop.subset(adata)  # subset adata to the image crop\nsq.im.calculate_image_features(adata_crop, crop, library_id=\"library_id\", layer=\"image\", features=\"summary\", n_jobs=4)\nadata_crop.obsm[\"img_features\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The calculated features can now be used in downstream Scanpy analyses,\nby e.g. using all Z dimensions to cluster spots based on image features\nand gene features.\n\nHere, we cluster genes and calculated features using a standard Scanpy\nworkflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc.pp.normalize_total(adata_crop, inplace=True)\nsc.pp.log1p(adata_crop)\nsc.pp.pca(adata_crop)\nsc.pp.neighbors(adata_crop)\nsc.tl.leiden(adata_crop)\n\nsc.pp.neighbors(adata_crop, use_rep=\"img_features\", key_added=\"neigh_features\")\nsc.tl.leiden(adata_crop, neighbors_key=\"neigh_features\", key_added=\"leiden_features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the result interactively using Napari, or statically using\n`scanpy.pl.spatial`:\n\n``` python\nimg.interactive(adata, library_key='library_id')\n```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc.pl.spatial(\n    adata_crop[adata_crop.obs[\"library_id\"] == library_ids[0]],\n    library_id=library_ids[0],\n    color=[\"leiden\", \"leiden_features\"],\n)\n\nsc.pl.spatial(\n    adata_crop[adata_crop.obs[\"library_id\"] == library_ids[1]],\n    library_id=library_ids[1],\n    color=[\"leiden\", \"leiden_features\"],\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}