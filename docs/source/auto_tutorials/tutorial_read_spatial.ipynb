{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import spatial data in AnnData and Squidpy\n==========================================\n\nThis tutorial shows how to store spatial datasets in `anndata.AnnData`.\n\nSpatial molecular data comes in many different formats, and to date\nthere is no one-size-fit-all solution for reading spatial data in\nPython. Scanpy already provides a solution for Visium Spatial\ntranscriptomics data with the function `scanpy.read_visium` but that is\nbasically it. Here in Squidpy, we do provide some pre-processed (and\npre-formatted) datasets, with the module `squidpy.datasets` but it\\'s\nnot very useful for the users who need to import their own data.\n\nIn this tutorial, we will showcase how spatial data are stored in\n`anndata.AnnData`. We will use mock datasets for this purpose, yet\nshowing with examples the important details that you should take care of\nin order to exploit the full functionality of the\n*AnnData-Scanpy-Squidpy* ecosystem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from anndata import AnnData\nimport scanpy as sc\nimport squidpy as sq\n\nfrom numpy.random import default_rng\n\nimport matplotlib.pyplot as plt\n\nsc.logging.print_header()\nprint(f\"squidpy=={sq.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Spatial coordinates in AnnData\n==============================\n\nFirst, let\\'s generate some data. We will need:\n\n> -   an array of features (e.g. counts).\n> -   an array of spatial coordinates.\n> -   an image array (e.g. the tissue image).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rng = default_rng(42)\ncounts = rng.integers(0, 15, size=(10, 100))  # feature matrix\ncoordinates = rng.uniform(0, 10, size=(10, 2))  # spatial coordinates\nimage = rng.uniform(0, 1, size=(10, 10, 3))  # image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\\'s first start with creating the `anndata.AnnData` object. We will\nfirst just use the count matrix and the spatial coordinates. Specify the\n`anndata.AnnData.obsm` key as [\\'spatial\\']{.title-ref} is not strictly\nnecessary but will save you a lot of typing since it\\'s the default for\nboth Squidpy and Scanpy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adata = AnnData(counts, obsm={\"spatial\": coordinates})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let\\'s run a standard Scanpy clustering and umap workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.umap(adata)\nsc.tl.leiden(adata)\nadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize the dummy cluster annotation `adata.obs['leiden']` in\nspace.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc.pl.spatial(adata, color=\"leiden\", spot_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tissue image in AnnData\n=======================\n\nFor use cases where there is no tissue image, this is all you need to\nstart using Scanpy/Squidpy for your analysis. For instance, you can\ncompute a spatial graph with `squidpy.gr.spatial_neighbors` based on a\nfixed neighbor radius that is informative given your experimental\nsettings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.gr.spatial_neighbors(adata, radius=3.0)\nsc.pl.spatial(adata, color=\"leiden\", neighbors_key=\"spatial_neighbors\", spot_size=1, edges=True, edges_width=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In case you do have an image of the tissue (or multiple, at different\nresolutions) this is what you need to know to correctly store it in\nAnnData. First, let\\'s visualize the mock image from before.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The image and its metadata are stored in the [uns]{.title-ref} slot of\n`anndata.AnnData`. Specifically, in the\n`adata.uns['spatial'][<library_id>]` slot, where\n[library\\_id]{.title-ref} is any unique key that refers to the tissue\nimage.\n\nFor now, we will assume that there is only one image. This is the\nnecessary metadata:\n\n> -   [tissue\\_hires\\_scalef]{.title-ref} - this is the scale factor\n>     between the spatial coordinates units and the image pixels. In the\n>     case of Visium, this is usually \\~0.17. In this case, we assume\n>     that the spatial coordinates are in the same scale of the pixels,\n>     and so we will set this value to 1.\n> -   [spot\\_diameter\\_fullres]{.title-ref} - this is the diameter of\n>     the capture area for each observation. In the case of Visium, we\n>     usually call them [\\\"spots\\\"]{.title-ref} and this value is set to\n>     \\~89.\n\nHere, we will set it to 0.5.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spatial_key = \"spatial\"\nlibrary_id = \"tissue42\"\nadata.uns[spatial_key] = {library_id: {}}\nadata.uns[spatial_key][library_id][\"images\"] = {}\nadata.uns[spatial_key][library_id][\"images\"] = {\"hires\": image}\nadata.uns[spatial_key][library_id][\"scalefactors\"] = {\"tissue_hires_scalef\": 1, \"spot_diameter_fullres\": 0.5}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We don\\'t provide the flexibility (yet) to change the values of such\nkeys. These are the keys provided by the Space Ranger output from 10x\nGenomics Visium and therefore were the first to be adopted. In the\nfuture, we might settle to a sightly different structure. But for now,\nif all such key are correct, `scanpy.pl.spatial` works out of the box.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc.pl.spatial(adata, color=\"leiden\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can fiddle around with the settings to see what changes. For\ninstance, let\\'s change [tissue\\_hires\\_scalef]{.title-ref} to half the\nprevious value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adata.uns[spatial_key][library_id][\"scalefactors\"] = {\"tissue_hires_scalef\": 0.5, \"spot_diameter_fullres\": 0.5}\nsc.pl.spatial(adata, color=\"leiden\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the spatial coordinates have been scaled down, and the\nimage was \\\"zoomed in\\\".\n\nOf course, you might want to \\\"analyze\\\" such image.\n`squidpy.im.ImageContainer` comes to the rescue! Just instantiate a new\nobject and it will work out of the box.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img = sq.im.ImageContainer(image)\nimg.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}