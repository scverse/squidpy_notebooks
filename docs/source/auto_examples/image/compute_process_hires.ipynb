{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Process a high-resolution image\n\nThis example shows how to use `squidpy.im.process` with tiling.\n\nThe function can be applied to any method (e.g., smoothing, conversion\nto grayscale) or `layer` of a high-resolution image layer of\n`squidpy.im.ImageContainer`.\n\nBy default, `squidpy.im.process` processes the entire input image at\nonce. In the case of high-resolution tissue slides however, the images\nmight be too big to fit in memory and cannot be processed at once. In\nthat case you can use the argument `chunks` to tile the image in crops\nof shape `chunks`, process each crop, and re-assemble the resulting\nimage. Note that you can also use `squidpy.im.segment` in this manner.\n\nNote that depending on the processing function used, there might be\nborder effects occurring at the edges of the crops. Since Squidpy is\nbacked by `dask`, and internally chunking is done using\n`dask.array.map_overlap`, dealing with these border effects is easy.\nJust specify the `depth` and `boundary` arguments in the `apply_kwargs`\nupon the call to `squidpy.im.process`. For more information, please\nrefer to the documentation of `dask.array.map_overlap`.\n\nFor the build in processing functions, [gray]{.title-ref} and\n[smooth]{.title-ref}, the border effects are already automatically taken\ncare of, so it is not necessary to specify `depth` and `boundary`. For\n`squidpy.im.segment`, the default `depth` is 30, which already takes\ncare of most severe border effects.\n\n::: seealso\n-   `sphx_glr_auto_examples_image_compute_smooth.py`.\n-   `sphx_glr_auto_examples_image_compute_gray.py`.\n-   `sphx_glr_auto_examples_image_compute_segment_fluo.py`.\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import squidpy as sq\n\nfrom scipy.ndimage import gaussian_filter\nimport numpy as np\n\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Built-in processing functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# load the H&E stained tissue image\nimg = sq.datasets.visium_hne_image()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will process the image by tiling it in crops of shape\n`chunks = (1000, 1000)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.process(img, layer=\"image\", method=\"gray\", chunks=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can look at the result on a cropped part of the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "crop = img.crop_corner(4000, 4000, size=2000)\n\nfig, axes = plt.subplots(1, 2)\ncrop.show(\"image\", ax=axes[0])\n_ = axes[0].set_title(\"original\")\ncrop.show(\"image_gray\", cmap=\"gray\", ax=axes[1])\n_ = axes[1].set_title(\"grayscale\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Custom processing functions\n\nHere, we use a custom processing function (here\n`scipy.ndimage.gaussian_filter`) with chunking to showcase the `depth`\nand `boundary` arguments.\n\nLets use a simple image and choose the chunk size in such a way to\nclearly see the differences between using overlapping crops and\nnon-overlapping crops.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "arr = np.zeros((20, 20))\narr[10:] = 1\nimg = sq.im.ImageContainer(arr, layer=\"image\")\n\n# smooth the image using `depth` 0 and 1\nsq.im.process(\n    img,\n    layer=\"image\",\n    method=gaussian_filter,\n    layer_added=\"smooth_depth0\",\n    chunks=10,\n    sigma=1,\n    apply_kwargs={\"depth\": 0},\n)\nsq.im.process(\n    img,\n    layer=\"image\",\n    method=gaussian_filter,\n    layer_added=\"smooth_depth1\",\n    chunks=10,\n    sigma=1,\n    apply_kwargs={\"depth\": 1, \"boundary\": \"reflect\"},\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the difference in results. Using overlapping blocks with\n`depth = 1` removes the artifacts at the borders between chunks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3)\nimg.show(\"image\", ax=axes[0])\n_ = axes[0].set_title(\"original\")\nimg.show(\"smooth_depth0\", ax=axes[1])\n_ = axes[1].set_title(\"non-overlapping crops\")\nimg.show(\"smooth_depth1\", ax=axes[2])\n_ = axes[2].set_title(\"overlapping crops\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}