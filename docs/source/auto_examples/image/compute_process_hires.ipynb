{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Process a high-resolution image\n===============================\n\nThis example shows how to use `squidpy.im.process` with tiling.\n\nThe function can be applied to any method (e.g., smoothing, conversion\nto grayscale) or `layer` of a high-resolution image layer of\n`squidpy.im.ImageContainer`.\n\nBy default, `squidpy.im.process` processes the entire input image at\nonce. In the case of high-resolution tissue slides however, the images\nmight be too big to fit in memory and cannot be processed at once. In\nthat case you can use the argument `size` to tile the image in crops of\nshape `size`, process each crop, and re-assemble the resulting image.\nNote that you can also use `squidpy.im.segment` in this manner.\n\nNote that depending on the processing function used, there might be\nborder effects occurring at the edges of the crops. In a future version,\nwe will support the extraction of overlapping crops, which can mitigate\nthese effects.\n\n::: {.seealso}\n-   `sphx_glr_auto_examples_image_compute_smooth.py`.\n-   `sphx_glr_auto_examples_image_compute_gray.py`.\n-   `sphx_glr_auto_examples_image_compute_segment_fluo.py`.\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import squidpy as sq\n\nimport matplotlib.pyplot as plt\n\n# load H&E stained tissue image\nimg = sq.datasets.visium_hne_image()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will process the image by tiling it in crops of shape\n`size = (1000, 1000)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.process(img, layer=\"image\", method=\"gray\", size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can look at the result on a cropped part of the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "crop = img.crop_corner(4000, 4000, size=2000)\n\nfig, axes = plt.subplots(1, 2)\ncrop.show(\"image\", ax=axes[0])\n_ = axes[0].set_title(\"original\")\ncrop.show(\"image_gray\", cmap=\"gray\", ax=axes[1])\n_ = axes[1].set_title(\"grayscale\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}