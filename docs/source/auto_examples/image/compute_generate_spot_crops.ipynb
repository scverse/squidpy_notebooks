{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate cropped images from spots\n==================================\n\nThis example shows how to use\n`squidpy.im.ImageContainer.generate_spot_crops`.\n\nHigh-resolution tissue slides might be too large to fit in the memory.\nTherefore, we use a generator that produces cropped images from the\noriginal image container object.\n`squidpy.im.ImageContainer.generate_spot_crops` iterates over\n`anndata.AnnData.obsm` and extracts crops.\n\nFor Z-stacks, the specified `library_id` or list of `library_id` need to\nmatch the name of the Z-dimension. Always extracts 2D crops from the\nspecified Z-dimension.\n\n::: {.seealso}\n\\- `sphx_glr_auto_examples_image_compute_crops.py` -\n`sphx_glr_auto_examples_image_compute_process_hires.py` -\n`sphx_glr_auto_examples_image_compute_gray.py`\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import squidpy as sq\n\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we load the H&E stained tissue image. Here, we only load a\ncropped dataset to speed things up. In general,\n`squidpy.im.ImageContainer.generate_spot_crops` can also process very\nlarge images. See\n`sphx_glr_auto_examples_image_compute_process_hires.py`. Second, we load\nthe related anndata for the H&E stained tissue image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "img = sq.datasets.visium_hne_image_crop()\nadata = sq.datasets.visium_hne_adata_crop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we use `squidpy.im.ImageContainer.generate_spot_crops` to make a\ngenerator that generates cropped images. The argument `as_array` specify\nthe type in which the crop is returned. If we pass a specific layer in\nthe `squidpy.im.ImageContainer` then it will return a plain\n`numpy.ndarray`. Check the documentation of the method\n`squidpy.im.ImageContainer.generate_spot_crops`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gen = img.generate_spot_crops(adata, scale=0.5, as_array=\"image\", squeeze=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When called, the `next(gen)` produces consecutive cropped images each\ntime. Let\\'s plot the cropped images using matplotlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 5)\nfig.set_size_inches((20, 6))\nfor i in range(5):\n    axes[i].set_title(f\"Cropped image {i+1}\")\n    axes[i].axis(\"off\")\n    axes[i].imshow(next(gen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now see how the cropped images differ with change in\n`spot_size`. `scale = 1` would crop the spot with exact diameter size.\nYou can crop larger area by increasing the `scale`. To illustrate this,\nwe change the spot\\_size and plot the images again by looping on\n`next(gen)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gen = img.generate_spot_crops(adata, scale=1.5, as_array=\"image\", squeeze=True)\nfig, axes = plt.subplots(1, 5)\nfig.set_size_inches((20, 6))\nfor i in range(5):\n    axes[i].set_title(f\"Cropped spot {i}\")\n    axes[i].axis(\"off\")\n    axes[i].imshow(next(gen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see the increase in the context with increase in the `spot_size`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gen = img.generate_spot_crops(adata, spot_scale=2, as_array=\"image\", squeeze=True)\nfig, axes = plt.subplots(1, 5)\nfig.set_size_inches((20, 6))\nfor i in range(5):\n    axes[i].set_title(f\"Cropped spot {i}\")\n    axes[i].axis(\"off\")\n    axes[i].imshow(next(gen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Argument `as_array` also takes boolean `True` to return a `dict` where\nthe keys are layers and values are `numpy.ndarray`. In this case, there\nis only one layer: `'image'`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gen = img.generate_spot_crops(adata, spot_scale=0.5, as_array=True, squeeze=True)\ndic = next(gen)\nimage = dic[\"image\"]\nplt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Passing `False` to the argument `as_array` returns a\n`squidpy.im.ImageContainer`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gen = img.generate_spot_crops(adata, spot_scale=2, as_array=False, squeeze=True)\nfor _ in range(5):\n    next(gen).show(figsize=(2, 2), dpi=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If `return_obs = True`, yields a `tuple` (cropped image, `obs_name`).\nOtherwise, yields just the crops. The type of the crops depends on\n`as_array` and the number of dimensions on `squeeze`. Such generator\ncould be used downstream in machine learning applications, where the\nclass label as well as the image is needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gen = img.generate_spot_crops(adata, spot_scale=2, as_array=\"image\", squeeze=True, return_obs=True)\nimage, obs_name = next(gen)\nplt.imshow(image)\nplt.title(obs_name)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}