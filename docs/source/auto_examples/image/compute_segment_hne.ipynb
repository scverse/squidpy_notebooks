{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Cell-segmentation for H&E stains\n\nThis example shows how to use processing and segmentation functions to\nsegment images with H&E stains. For a general example of how to use\n`squidpy.im.segment_img`{.interpreted-text role=\"func\"} see\n`sphx_glr_auto_examples_image_compute_segment_fluo.py`{.interpreted-text\nrole=\"ref\"}.\n\nHere, we attempt to segment a noisy H&E stain. Note that we only provide\nvery basic segmentation models. If you require precise cell-segmentation\nand cell-counts, you might want to add more pre-processing and / or use\na pre-trained model to do the segmentation (using\n`squidpy.im.SegmentationModelTensorflow`{.interpreted-text\nrole=\"class\"}).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import squidpy as sq\n\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# load H&E stained tissue image and crop to a smaller segment\nimg = sq.datasets.visium_hne_image_crop()\ncrop = img.crop_corner(0, 0, 1000, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before segmenting the image, we do some preprocessing using\n`squidpy.im.process_img`{.interpreted-text role=\"func\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# convert to grayscale\nsq.im.process_img(crop, img_id=\"image\", processing=\"gray\")\n# smooth image\nsq.im.process_img(crop, img_id=\"image_gray\", processing=\"smooth\", sigma=4)\n\n# plot the result\nfig, axes = plt.subplots(1, 3)\nfor img_id, ax in zip([\"image\", \"image_gray\", \"image_gray_smooth\"], axes):\n    ax.imshow(np.squeeze(crop[img_id]))\n    ax.set_title(img_id)\n    ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finding a good threshold for the segmentation is more difficult than for\na DAPI stain, as there is no distinct peak in the histogram. Judging by\nthe plot showing values smaller than 0.28, this threshold seems to be a\ngood choice for this example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\naxes[0].imshow(crop[\"image_gray_smooth\"][:, :, 0] < 0.28)\naxes[0].axis(\"off\")\n_ = sns.histplot(np.array(crop[\"image_gray_smooth\"]).flatten(), bins=50, ax=axes[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use `squidpy.im.segment_img`{.interpreted-text role=\"func\"} with\n`mode=\"watershed\"` to do the segmentation. Since, opposite to the\nfluorescence DAPI stain, in the H&E stain, nuclei appear darker, we need\nto indicate the model that it should treat lower-intensity values as\nforeground. We do this by specifying the `geq=False` in the `kwargs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.segment_img(img=crop, img_id=\"image_gray_smooth\", model_group=\"watershed\", thresh=0.28, geq=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The segmented crop is saved in the layer\n[segmented_watershed]{.title-ref}. This behaviour can be changed with\nthe arguments `copy` and `key_added`. The result of the segmentation is\na label image that can be used to extract features like the number of\ncells from the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(crop)\nprint(f\"number of segments in crop: {len(np.unique(crop['segmented_watershed']))}\")\n\nfig, axes = plt.subplots(1, 2)\naxes[0].imshow(crop[\"image_gray_smooth\"][:, :, 0])\naxes[0].set_title(\"H&E\")\naxes[1].imshow(crop[\"segmented_watershed\"].squeeze(), cmap=\"jet\", interpolation=\"none\")\naxes[1].set_title(\"segmentation\")\nfor ax in axes:\n    ax.axis(\"off\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}