{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Advanced Cell-segmentation for H&E stains\n\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\--\n\nThis example shows how to use processing and segmentation functions to\nsegment images with H&E stains. For a general example of how to use\n`squidpy.im.segment_img`{.interpreted-text role=\"func\"} see\n`sphx_glr_auto_examples_image_compute_segment_fluo.py`{.interpreted-text\nrole=\"ref\"}.\n\nHere, we attempt to segment a noisy H&E stain. Note that we only provide\nvery basic segmentation models. If you require precise cell-segmentation\nand cell-counts, you might want to add more pre-processing and / or use\na pre-trained model to do the segmentation (using\n`squidpy.im.SegmentationModelTensorflow`{.interpreted-text\nrole=\"class\"}).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\n# import modules\nimport squidpy as sq\n\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# load H&E stained tissue image\nimg = sq.im.ImageContainer(os.path.expanduser(\"~/.cache/squidpy/tutorial_data/visium_hne_crop.tiff\"))\n# crop a smaller image to segment\ncrop = img.crop_corner(0, 0, 1000, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before segmenting the image, we add some preprocessing using\n`squidpy.im.process_img`{.interpreted-text role=\"func\"}. convert to\ngrayscale\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.process_img(crop, img_id=\"image\", processing=\"gray\")\n# smooth image\nsq.im.process_img(crop, img_id=\"image_gray\", processing=\"smooth\", sigma=4)\n\n# plot the result\nfig, axes = plt.subplots(1, 3, figsize=(8, 15))\nfor img_id, ax in zip([\"image\", \"image_gray\", \"image_gray_smooth\"], axes):\n    ax.imshow(np.squeeze(crop[img_id]))\n    ax.set_title(img_id)\n    ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finding a good threshold for the segmentation is more difficult than for\na DAPI stain, as there is no distinct peak in the histogram. A threshold\nof 0.28 seems to be a good choice for this example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\naxes[0].imshow(crop[\"image_gray_smooth\"][:, :, 0] < 0.28)\naxes[0].axis(\"off\")\nsns.histplot(np.array(crop[\"image_gray_smooth\"]).flatten(), bins=50, ax=axes[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We segment `squidpy.im.segment_img`{.interpreted-text role=\"func\"} with\n`mode=\"watershed\"` to do the segmentation. Since, opposite to the\nfluorescence DAPI stain, in the H&E stain, nuclei appear darker, we need\nto indicate the model that it should treat lower-intensity values as\nforeground. We do this by specifying the `geq = False` in the `kwargs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.segment_img(\n    img=crop, img_id=\"image_gray_smooth\", model_group=\"watershed\", thresh=0.28, geq=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The segmented crop is saved in the layer\n[segmented_watershed]{.title-ref}. This behavour can be changed with the\narguments `copy` and `key_added`. The result of the segmentation is a\nlabel image that can be used to extract features like number of cells\nfrom the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(crop)\nprint(f\"number of segments in crop: {len(np.unique(crop['segmented_watershed']))}\")\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 20))\naxes[0].imshow(crop[\"image_gray_smooth\"][:, :, 0])\naxes[0].set_title(\"H&E\")\naxes[1].imshow(crop[\"segmented_watershed\"][:, :, 0], cmap=\"jet\", interpolation=\"none\")\naxes[1].set_title(\"segmentation\")\nfor ax in axes:\n    ax.axis(\"off\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}