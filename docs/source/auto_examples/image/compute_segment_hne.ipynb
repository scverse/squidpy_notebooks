{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell-segmentation for H&E stains\n\nThis example shows how to use processing and segmentation functions to\nsegment images with H&E stains.\n\nFor a general example of how to use `squidpy.im.segment`, see\n`sphx_glr_auto_examples_image_compute_segment_fluo.py`.\n\nNote that we only provide a basic built-in segmentation model. If you\nrequire precise cell-segmentation and cell-counts, you might want to add\nmore pre-processing and/or use a pre-trained model to do the\nsegmentation (using `squidpy.im.SegmentationCustom`).\n\n::: seealso\n-   `sphx_glr_auto_examples_image_compute_segment_fluo.py` for an\n    example on how to calculate a cell-segmentation of a fluorescence\n    image.\n-   [Nuclei Segmentation using\n    Cellpose](../../external_tutorials/tutorial_cellpose_segmentation.ipynb)\n    for a tutorial on using Cellpose as a custom segmentation function.\n-   [Nuclei Segmentation using\n    StarDist](../../external_tutorials/tutorial_stardist.ipynb) for a\n    tutorial on using StarDist as a custom segmentation function.\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import squidpy as sq\n\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# load the H&E stained tissue image and crop to a smaller segment\nimg = sq.datasets.visium_hne_image_crop()\ncrop = img.crop_corner(0, 0, size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before segmenting the image, we smooth it using `squidpy.im.process`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# smooth image\nsq.im.process(crop, layer=\"image\", method=\"smooth\", sigma=4)\n\n# plot the result\nfig, axes = plt.subplots(1, 2)\nfor layer, ax in zip([\"image\", \"image_smooth\"], axes):\n    crop.show(layer, ax=ax)\n    ax.set_title(layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use channel 0 to do the segmentation, as this channel contains\nmost of the nuclei information within an H&E stain. Instead of using\nautomatic threshold with [Otsu\\'s\nmethod](https://en.wikipedia.org/wiki/Otsu%27s_method), we will define a\nmanual fixed threshold. Note that using Otsu\\'s method to determine the\nthreshold also yields good results.\n\nJudging by peak in the histogram and the thresholded example image, a\nthreshold of 90, seems to be a good choice for this example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\ncrop.show(\"image_smooth\", cmap=\"gray\", ax=axes[0])\naxes[1].imshow(crop[\"image_smooth\"][:, :, 0, 0] < 90)\n_ = sns.histplot(np.array(crop[\"image_smooth\"]).flatten(), bins=50, ax=axes[2])\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use `squidpy.im.segment` with `method = 'watershed'` to do the\nsegmentation. Since, opposite to the fluorescence DAPI stain, in the H&E\nstain nuclei appear darker, we need to indicate to the model that it\nshould treat lower-intensity values as foreground. We do this by\nspecifying the `geq = False` in the `kwargs`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.segment(img=crop, layer=\"image_smooth\", method=\"watershed\", thresh=90, geq=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The segmented crop is saved in the layer\n[segmented_watershed]{.title-ref}. This behavior can be changed with the\narguments `copy` and `layer_added`. The result of the segmentation is a\nlabel image that can be used to extract features like the number of\ncells from the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(crop)\nprint(f\"Number of segments in crop: {len(np.unique(crop['segmented_watershed']))}\")\n\nfig, axes = plt.subplots(1, 2)\ncrop.show(\"image\", channel=0, ax=axes[0])\n_ = axes[0].set_title(\"H&E\")\ncrop.show(\"segmented_watershed\", cmap=\"jet\", interpolation=\"none\", ax=axes[1])\n_ = axes[1].set_title(\"segmentation\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}