{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract image features\n\nThis example shows the computation of spot-wise features from Visium\nimages.\n\nVisium datasets contain high-resolution images of the tissue in addition\nto the spatial gene expression measurements per spot (*obs*). In this\nnotebook, we extract features for each spot from an image using\n`squidpy.im.calculate_image_features` and create a **obs x features**\nmatrix that can be analyzed together with the **obs x genes** spatial\ngene expression matrix.\n\n::: seealso\nWe provide different feature extractors that are described in more\ndetail in the following examples:\n\n-   See `sphx_glr_auto_examples_image_compute_summary_features.py` on\n    how to calculate summary statistics of each color channel.\n-   See `sphx_glr_auto_examples_image_compute_texture_features.py` on\n    how to calculate texture features based on repeating patterns.\n-   See `sphx_glr_auto_examples_image_compute_histogram_features.py` on\n    how to calculate color histogram features.\n-   See `sphx_glr_auto_examples_image_compute_segmentation_features.py`\n    on how to calculate number and size of objects from a binary\n    segmentation layer.\n-   See `sphx_glr_auto_examples_image_compute_custom_features.py` on how\n    to calculate custom features by providing any feature extraction\n    function.\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\nimport squidpy as sq\n\nimport numpy as np\n\nimport seaborn as sns\n\n# get spatial dataset including high-resolution tissue image\nimg = sq.datasets.visium_hne_image_crop()\nadata = sq.datasets.visium_hne_adata_crop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The high-resolution tissue image is contained in `img['image']`, and the\nspot locations coordinates are stored in `adata.obsm['spatial']`. We can\nplot the spots overlayed on a lower-resolution version of the tissue\nimage contained in `adata`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(threshold=10)\nprint(img)\nprint(adata.obsm[\"spatial\"])\n\nsc.set_figure_params(figsize=(4, 4))\nsc.pl.spatial(adata, add_outline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using this information, we can now extract features from the tissue\nunderneath each spot by calling `squidpy.im.calculate_image_features`.\nThis function takes both `adata` and `img` as input, and will write the\nresulting `obs x features` matrix to `adata.obsm[<key>]`. It contains\nseveral arguments to modify its behavior. With these arguments you can:\n\n> -   specify the image used for feature calculation using `layer`.\n> -   specify the type of features that should be calculated using\n>     `features` and `features_kwargs`.\n> -   specify how the crops used for feature calculation look like using\n>     `kwargs`.\n> -   specify parallelization options using `n_jobs`, `backend`, and\n>     `show_progress_bar`.\n> -   specify how the data is returned using `key_added` and `copy`.\n\nLet us first calculate summary features and save the result in\n`adata.obsm['features']`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.calculate_image_features(adata, img, features=\"summary\", key_added=\"features\", show_progress_bar=False)\n\n# show the calculated features\nadata.obsm[\"features\"].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To visualize the features, we can use `squidpy.pl.extract` to plot the\ntexture features on the tissue image.\n\nHere, we plot the median values of all channels\n([summary_ch-0_quantile-0.5]{.title-ref},\n[summary_ch-0_quantile-0.5]{.title-ref}, and\n[summary_ch-2_quantile-0.5]{.title-ref}).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc.pl.spatial(\n    sq.pl.extract(adata, \"features\"),\n    color=[\"summary_ch-0_quantile-0.5\", \"summary_ch-0_quantile-0.5\", \"summary_ch-2_quantile-0.5\"],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Specify crop appearance\n\nFeatures are extracted from image crops that capture the Visium spots\n(see also `sphx_glr_auto_examples_image_compute_crops.py`). By default,\nthe crops have the same size as the spot, are not scaled and square. We\ncan use the `mask_circle` argument to mask a circle and ensure that only\ntissue underneath the round Visium spots is taken into account to\ncompute the features. Further, we can set `scale` and `spot_scale`\narguments to change how the crops are generated. For more details on the\ncrop computation, see also\n`sphx_glr_auto_examples_image_compute_crops.py`.\n\n> -   Use `mask_circle = True, scale = 1, spot_scale = 1`, if you would\n>     like to get features that are calculated only from tissue in a\n>     Visium spot.\n> -   Use `scale = X`, with [X \\< 1]{.title-ref}, if you would like to\n>     downscale the crop before extracting the features.\n> -   Use `spot_scale = X`, with [X \\> 1]{.title-ref}, if you want to\n>     extract crops that are X-times the size of the Visium spot.\n\nLet us extract masked and scaled features and compare them.\n\nWe subset `adata` to the first 50 spots to make the computation of\nfeatures fast. Skip this step if you want to calculate features from all\nspots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adata_sml = adata[:50].copy()\n\n# calculate default features\nsq.im.calculate_image_features(\n    adata_sml, img, features=[\"summary\", \"texture\", \"histogram\"], key_added=\"features\", show_progress_bar=False\n)\n# calculate features with masking\nsq.im.calculate_image_features(\n    adata_sml,\n    img,\n    features=[\"summary\", \"texture\", \"histogram\"],\n    key_added=\"features_masked\",\n    mask_circle=True,\n    show_progress_bar=False,\n)\n# calculate features with scaling and larger context\nsq.im.calculate_image_features(\n    adata_sml,\n    img,\n    features=[\"summary\", \"texture\", \"histogram\"],\n    key_added=\"features_scaled\",\n    mask_circle=True,\n    spot_scale=2,\n    scale=0.5,\n    show_progress_bar=False,\n)\n\n# plot distribution of median for different cropping options\n_ = sns.displot(\n    {\n        \"features\": adata_sml.obsm[\"features\"][\"summary_ch-0_quantile-0.5\"],\n        \"features_masked\": adata_sml.obsm[\"features_masked\"][\"summary_ch-0_quantile-0.5\"],\n        \"features_scaled\": adata_sml.obsm[\"features_scaled\"][\"summary_ch-0_quantile-0.5\"],\n    },\n    kind=\"kde\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The masked features have lower median values, because the area outside\nthe circle is masked with zeros.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parallelization\n\nSpeeding up the feature extraction is easy. Just set the `n_jobs` flag\nto the number of jobs that should be used by\n`squidpy.im.calculate_image_features`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.calculate_image_features(adata, img, features=\"summary\", key_added=\"features\", n_jobs=4, show_progress_bar=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}