{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract Image Features\n\nIn addition to the spatial gene expression values, visium datasets also\ncontain high-resolution images of the tissue. In this notebook we\nextract features from this image using\n`squidpy.im.calculate_image_features`{.interpreted-text role=\"func\"} and\ncreate a `obs x features` matrix that can be analysed together with the\n`obs x genes` spatial gene expression matrix.\n\nTo compute features for each visium spot (`obs`), we extract image crops\nfrom the tissue image centered on each spot. When extracting the crops,\nwe can specify the size and scale of the crops and optionally mask a\ncircle to ensure that only tissue underneath the round visium spots is\ntaken into account to compute the features. See also\n`sphx_glr_auto_examples_image_compute_crops.py`{.interpreted-text\nrole=\"ref\"}.\n\nThe extracted crops are then used to compute features. We provide\ndifferent feature extractors that are described in more detail in the\nfollowing examples:\n\n-   summary statistics of each color channel\n    (`sphx_glr_auto_examples_image_compute_summary_features.py`{.interpreted-text\n    role=\"ref\"})\n-   texture features based on repeating patterns\n    (`sphx_glr_auto_examples_image_compute_texture_features.py`{.interpreted-text\n    role=\"ref\"})\n-   color histogram features using counts in bins of each channel\\'s\n    histogram\n    (`sphx_glr_auto_examples_image_compute_histogram_features.py`{.interpreted-text\n    role=\"ref\"})\n-   number and size of objects from a binary segmentation layer\n    (`sphx_glr_auto_examples_image_compute_segmentation_features.py`{.interpreted-text\n    role=\"ref\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nimport squidpy as sq\n\nimport scanpy as sc\n\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# get spatial dataset including hires tissue image\nimg = sq.datasets.visium_hne_image_crop()\nadata = sq.datasets.visium_hne_adata_crop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The high resolution tissue image is contained in `img['image']`, and the\nspot locations in tissue image pixel-space are located in\n`adata.obsm['spatial']`. We can plot the spots overlayed on a\nlower-resolution version of the tissue image contained in adata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(threshold=10)\nprint(img)\nprint(adata.obsm[\"spatial\"])\n\nsc.pl.spatial(adata, add_outline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using this information, we can now extract features from the tissue\nunderneath each spot by calling\n`squidpy.im.calculate_image_features`{.interpreted-text role=\"func\"}.\nThis function takes both `adata` and `img` as input, and will write the\nresulting `obs x features` matrix to `adata.obsm[key]`. It contains\nseveral arguments to modify its behaviour. With these arguments you can\n\n-   specify the image used for feature calculation using `img_id`,\n-   specify the type of features that should be calculated using\n    `features` and `features_kwargs`,\n-   specify how the crops used for feature calculation look like using\n    `kwargs`,\n-   specify parallelization options using `n_jobs`, `backend`,\n    `show_progress_bar`, and\n-   specify how the data that is returned using `key_added`, `copy`.\n\nLet us first calculate summary features and save the result in\n`adata.obsm['features']`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.calculate_image_features(adata, img, features=\"summary\", key_added=\"features\")\n\n# show the calculated features\nprint(f\"calculated features: {list(adata.obsm['features'].columns)}\")\nadata.obsm[\"features\"].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To visualize the features, we can use\n`squidpy.pl.extract`{.interpreted-text role=\"func\"} to plot the texture\nfeatures on the tissue image. See\n`sphx_glr_auto_examples_plotting_compute_extract.py`{.interpreted-text\nrole=\"ref\"} for more details on this function.\n\nHere, we plot the median value of channel 0\n(`summary_quantile_0.5_ch_0`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc.pl.spatial(sq.pl.extract(adata, \"features\"), color=[None, \"summary_quantile_0.5_ch_0\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Speed up feature extraction\n\nSpeeding up the feature extraction is easy. Just set the `n_jobs` flag\nto the number of jobs that should be used by\n`squidpy.im.calculate_image_features`{.interpreted-text role=\"func\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# extract features by using 4 jobs\nsq.im.calculate_image_features(adata, img, features=\"summary\", key_added=\"features\", n_jobs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Specify crop appearance\n\nFeatures are extracted from image crops that are centered on the visium\nspots (see also\n`sphx_glr_auto_examples_image_compute_crops.py`{.interpreted-text\nrole=\"ref\"}). By default, the crops have the same size as the spot, are\nnot scaled and not masked. We can use the `mask_circle`, `scale`, and\n`size` arguments to change how the crops are generated.\n\n-   Use `mask_circle=True, scale=1, size=1`, if you would like to get\n    features that are calculated only from tissue in a visium spot\n-   Use `scale=X`, with [X \\< 1]{.title-ref}, if you would like to\n    downscale the crop before extracting the features\n-   Use `size=X`, with [X \\> 1]{.title-ref}, if you would like to\n    extract crops that are X-times the size of the visium spot\n\nLet us extract masked and scaled features and compare them\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We subset adata to the first 50 spots to make the computation of features fast.\n# Skip this step if you want to calculate features from all spots\nadata_sml = adata[0:50].copy()\n\n# calculate default features\nsq.im.calculate_image_features(adata_sml, img, features=[\"summary\", \"texture\", \"histogram\"], key_added=\"features\")\n# calculate features with masking\nsq.im.calculate_image_features(\n    adata_sml, img, features=[\"summary\", \"texture\", \"histogram\"], key_added=\"features_masked\", mask_circle=True\n)\n# calculate features with scaling and larger context\nsq.im.calculate_image_features(\n    adata_sml,\n    img,\n    features=[\"summary\", \"texture\", \"histogram\"],\n    key_added=\"features_scaled\",\n    mask_circle=True,\n    size=2,\n    scale=0.5,\n)\n\n# plot distribution of median for different cropping options\n_ = sns.displot({'features':\n             adata_sml.obsm[\"features\"][\"summary_quantile_0.5_ch_0\"],\n             'features_masked':\n             adata_sml.obsm[\"features_masked\"][\"summary_quantile_0.5_ch_0\"],\n             'features_scaled':\n             adata_sml.obsm[\"features_scaled\"][\"summary_quantile_0.5_ch_0\"]},\n           kind='kde')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The masked features have lower median values, because the area outside\nthe circle is masked with zeros.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}