{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract image features\n======================\n\nThis example shows the computation of spot-wise features from Visium\nimages.\n\nVisium datasets contain high-resolution images of the tissue in addition\nto the spatial gene expression measurements per spot (*obs*). In this\nnotebook, we extract features for each spot from an image using\nsquidpy.im.calculate\\_image\\_features and create a **obs x features**\nmatrix that can be analyzed together with the **obs x genes** spatial\ngene expression matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\nimport squidpy as sq\n\nimport numpy as np\n\nimport seaborn as sns\n\n# get spatial dataset including high-resolution tissue image\nimg = sq.datasets.visium_hne_image_crop()\nadata = sq.datasets.visium_hne_adata_crop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The high-resolution tissue image is contained in `img['image']`, and the\nspot locations coordinates are stored in `adata.obsm['spatial']`. We can\nplot the spots overlayed on a lower-resolution version of the tissue\nimage contained in `adata`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(threshold=10)\nprint(img)\nprint(adata.obsm[\"spatial\"])\n\nsc.set_figure_params(figsize=(4, 4))\nsc.pl.spatial(adata, add_outline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using this information, we can now extract features from the tissue\nunderneath each spot by calling squidpy.im.calculate\\_image\\_features.\nThis function takes both `adata` and `img` as input, and will write the\nresulting `obs x features` matrix to `adata.obsm[key]`. It contains\nseveral arguments to modify its behavior. With these arguments you can\n\n-   specify the image used for feature calculation using `layer`,\n-   specify the type of features that should be calculated using\n    `features` and `features_kwargs`,\n-   specify how the crops used for feature calculation look like using\n    `kwargs`,\n-   specify parallelization options using `n_jobs`, `backend`, and\n    `show_progress_bar`,\n-   specify how the data is returned using `key_added` and `copy`.\n\nLet us first calculate summary features and save the result in\n`adata.obsm['features']`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.calculate_image_features(adata, img, features=\"summary\", key_added=\"features\", show_progress_bar=False)\n\n# show the calculated features\nadata.obsm[\"features\"].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To visualize the features, we can use squidpy.pl.extract to plot the\ntexture features on the tissue image.\n\nHere, we plot the median values of all channels\n(summary\\_ch-0\\_quantile-0.5, summary\\_ch-0\\_quantile-0.5, and\nsummary\\_ch-2\\_quantile-0.5).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc.pl.spatial(\n    sq.pl.extract(adata, \"features\"),\n    color=[\"summary_ch-0_quantile-0.5\", \"summary_ch-0_quantile-0.5\", \"summary_ch-2_quantile-0.5\"],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify crop appearance\n=======================\n\nFeatures are extracted from image crops that capture the Visium spots\n(see also sphx\\_glr\\_auto\\_examples\\_image\\_compute\\_crops.py). By\ndefault, the crops have the same size as the spot, are not scaled and\nsquare. We can use the `mask_circle` argument to mask a circle and\nensure that only tissue underneath the round Visium spots is taken into\naccount to compute the features. Further, we can set `scale` and\n`spot_scale` arguments to change how the crops are generated. For more\ndetails on the crop computation, see also\nsphx\\_glr\\_auto\\_examples\\_image\\_compute\\_crops.py.\n\n-   Use `mask_circle=True, scale=1, spot_scale=1`, if you would like to\n    get features that are calculated only from tissue in a Visium spot\n-   Use `scale=X`, with X &lt; 1, if you would like to downscale the\n    crop before extracting the features\n-   Use `spot_scale=X`, with X &gt; 1, if you would like to extract\n    crops that are X-times the size of the Visium spot\n\nLet us extract masked and scaled features and compare them\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We subset adata to the first 50 spots to make the computation of features fast.\n# Skip this step if you want to calculate features from all spots\nadata_sml = adata[:50].copy()\n\n# calculate default features\nsq.im.calculate_image_features(\n    adata_sml, img, features=[\"summary\", \"texture\", \"histogram\"], key_added=\"features\", show_progress_bar=False\n)\n# calculate features with masking\nsq.im.calculate_image_features(\n    adata_sml,\n    img,\n    features=[\"summary\", \"texture\", \"histogram\"],\n    key_added=\"features_masked\",\n    mask_circle=True,\n    show_progress_bar=False,\n)\n# calculate features with scaling and larger context\nsq.im.calculate_image_features(\n    adata_sml,\n    img,\n    features=[\"summary\", \"texture\", \"histogram\"],\n    key_added=\"features_scaled\",\n    mask_circle=True,\n    spot_scale=2,\n    scale=0.5,\n    show_progress_bar=False,\n)\n\n# plot distribution of median for different cropping options\n_ = sns.displot(\n    {\n        \"features\": adata_sml.obsm[\"features\"][\"summary_ch-0_quantile-0.5\"],\n        \"features_masked\": adata_sml.obsm[\"features_masked\"][\"summary_ch-0_quantile-0.5\"],\n        \"features_scaled\": adata_sml.obsm[\"features_scaled\"][\"summary_ch-0_quantile-0.5\"],\n    },\n    kind=\"kde\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The masked features have lower median values, because the area outside\nthe circle is masked with zeros.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parallelization\n===============\n\nSpeeding up the feature extraction is easy. Just set the `n_jobs` flag\nto the number of jobs that should be used by\nsquidpy.im.calculate\\_image\\_features. extract features by using 4 jobs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.calculate_image_features(adata, img, features=\"summary\", key_added=\"features\", n_jobs=4, show_progress_bar=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}