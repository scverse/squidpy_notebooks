{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract Image Features\n\nThis example explains the computation of spot-wise features from visium\nimages.\n\nVisium datasets contain high-resolution images of the tissue in addition\nto the spatial gene expression measurements per spot\n([obs]{.title-ref}). In this notebook, we extract features for each spot\nfrom an image using `squidpy.im.calculate_image_features` and create a\n`obs x features` matrix that can be analysed together with the\n`obs x genes` spatial gene expression matrix.\n\nWe provide different feature extractors that are described in more\ndetail in the following examples:\n\n-   summary statistics of each color channel\n    (`sphx_glr_auto_examples_image_compute_summary_features.py`)\n-   texture features based on repeating patterns\n    (`sphx_glr_auto_examples_image_compute_texture_features.py`)\n-   color histogram features using counts in bins of each channel\\'s\n    histogram\n    (`sphx_glr_auto_examples_image_compute_histogram_features.py`)\n-   number and size of objects from a binary segmentation layer\n    (`sphx_glr_auto_examples_image_compute_segmentation_features.py`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\nimport squidpy as sq\n\nimport numpy as np\n\nimport seaborn as sns\n\n# get spatial dataset including high-resolution tissue image\nimg = sq.datasets.visium_hne_image_crop()\nadata = sq.datasets.visium_hne_adata_crop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The high-resolution tissue image is contained in `img['image']`, and the\nspot locations coordinates are stored in `adata.obsm['spatial']`. We can\nplot the spots overlayed on a lower-resolution version of the tissue\nimage contained in adata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(threshold=10)\nprint(img)\nprint(adata.obsm[\"spatial\"])\n\nsc.set_figure_params(figsize=(4, 4))\nsc.pl.spatial(adata, add_outline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using this information, we can now extract features from the tissue\nunderneath each spot by calling `squidpy.im.calculate_image_features`.\nThis function takes both `adata` and `img` as input, and will write the\nresulting `obs x features` matrix to `adata.obsm[key]`. It contains\nseveral arguments to modify its behaviour. With these arguments you can\n\n-   specify the image used for feature calculation using `img_id`,\n-   specify the type of features that should be calculated using\n    `features` and `features_kwargs`,\n-   specify how the crops used for feature calculation look like using\n    `kwargs`,\n-   specify parallelization options using `n_jobs`, `backend`, and\n    `show_progress_bar`,\n-   specify how the data that is returned using `key_added` and `copy`.\n\nLet us first calculate summary features and save the result in\n`adata.obsm['features']`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.calculate_image_features(adata, img, features=\"summary\", key_added=\"features\")\n\n# show the calculated features\nprint(f\"calculated features: {list(adata.obsm['features'].columns)}\")\nadata.obsm[\"features\"].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To visualize the features, we can use `squidpy.pl.extract` to plot the\ntexture features on the tissue image. See\n`sphx_glr_auto_examples_plotting_compute_extract.py` for more details on\nthis function.\n\nHere, we plot the median values of all channels\n([summary_quantile_0.5_ch_0]{.title-ref},\n[summary_quantile_0.5_ch_1]{.title-ref} and\n[summary_quantile_0.5_ch_2]{.title-ref}).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sc.pl.spatial(\n    sq.pl.extract(adata, \"features\"),\n    color=[\"summary_quantile_0.5_ch_0\", \"summary_quantile_0.5_ch_1\", \"summary_quantile_0.5_ch_2\"],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Specify crop appearance\n\nFeatures are extracted from image crops that capture the visium spots\n(see also `sphx_glr_auto_examples_image_compute_crops.py`). By default,\nthe crops have the same size as the spot, are not scaled and square. We\ncan use the `mask_circle` argument to mask a circle and ensure that only\ntissue underneath the round visium spots is taken into account to\ncompute the features. Further, we can set `scale` and `size` arguments\nto change how the crops are generated. For more details on the crop\ncomputation, see also `sphx_glr_auto_examples_image_compute_crops.py`.\n\n-   Use `mask_circle=True, scale=1, size=1`, if you would like to get\n    features that are calculated only from tissue in a visium spot\n-   Use `scale=X`, with [X \\< 1]{.title-ref}, if you would like to\n    downscale the crop before extracting the features\n-   Use `size=X`, with [X \\> 1]{.title-ref}, if you would like to\n    extract crops that are X-times the size of the visium spot\n\nLet us extract masked and scaled features and compare them\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We subset adata to the first 50 spots to make the computation of features fast.\n# Skip this step if you want to calculate features from all spots\nadata_sml = adata[0:50].copy()\n\n# calculate default features\nsq.im.calculate_image_features(adata_sml, img, features=[\"summary\", \"texture\", \"histogram\"], key_added=\"features\")\n# calculate features with masking\nsq.im.calculate_image_features(\n    adata_sml, img, features=[\"summary\", \"texture\", \"histogram\"], key_added=\"features_masked\", mask_circle=True\n)\n# calculate features with scaling and larger context\nsq.im.calculate_image_features(\n    adata_sml,\n    img,\n    features=[\"summary\", \"texture\", \"histogram\"],\n    key_added=\"features_scaled\",\n    mask_circle=True,\n    size=2,\n    scale=0.5,\n)\n\n# plot distribution of median for different cropping options\n_ = sns.displot(\n    {\n        \"features\": adata_sml.obsm[\"features\"][\"summary_quantile_0.5_ch_0\"],\n        \"features_masked\": adata_sml.obsm[\"features_masked\"][\"summary_quantile_0.5_ch_0\"],\n        \"features_scaled\": adata_sml.obsm[\"features_scaled\"][\"summary_quantile_0.5_ch_0\"],\n    },\n    kind=\"kde\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The masked features have lower median values, because the area outside\nthe circle is masked with zeros.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parallelisation\n\nSpeeding up the feature extraction is easy. Just set the `n_jobs` flag\nto the number of jobs that should be used by\n`squidpy.im.calculate_image_features`. extract features by using 4 jobs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.calculate_image_features(adata, img, features=\"summary\", key_added=\"features\", n_jobs=4)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}