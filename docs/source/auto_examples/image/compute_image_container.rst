
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/image/compute_image_container.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_image_compute_image_container.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_image_compute_image_container.py:


ImageContainer object
---------------------

This example shows how to use :class:`squidpy.im.ImageContainer` to interact with image structured data.

.. seealso::

    See :ref:`sphx_glr_auto_examples_image_compute_crops.py` for examples how to crop images using
    :class:`squidpy.im.ImageContainer`.

.. GENERATED FROM PYTHON SOURCE LINES 13-16

.. code-block:: default


    import squidpy as sq








.. GENERATED FROM PYTHON SOURCE LINES 17-20

Load a pre-loaded image.
To load your own data, use the ImageContainer constructor:
``squidpy.im.ImageContainer(<image-path-or-array>)``

.. GENERATED FROM PYTHON SOURCE LINES 20-22

.. code-block:: default

    img = sq.datasets.visium_hne_image()





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      0%|          | 0.00/380M [00:00<?, ?B/s]      0%|          | 40.0k/380M [00:00<22:26, 296kB/s]      0%|          | 208k/380M [00:00<07:52, 843kB/s]       0%|          | 864k/380M [00:00<02:30, 2.64MB/s]      1%|          | 3.41M/380M [00:00<00:43, 9.15MB/s]      2%|2         | 8.92M/380M [00:00<00:18, 20.6MB/s]      4%|3         | 14.6M/380M [00:00<00:13, 27.9MB/s]      5%|5         | 20.3M/380M [00:00<00:11, 32.8MB/s]      7%|6         | 26.1M/380M [00:01<00:10, 36.0MB/s]      8%|8         | 31.8M/380M [00:01<00:09, 38.0MB/s]     10%|9         | 37.5M/380M [00:01<00:09, 39.4MB/s]     11%|#1        | 43.3M/380M [00:01<00:08, 40.6MB/s]     13%|#2        | 49.0M/380M [00:01<00:08, 41.2MB/s]     14%|#4        | 54.7M/380M [00:01<00:08, 41.4MB/s]     16%|#5        | 60.4M/380M [00:01<00:08, 41.7MB/s]     17%|#7        | 66.1M/380M [00:02<00:07, 41.9MB/s]     19%|#8        | 71.9M/380M [00:02<00:07, 42.3MB/s]     20%|##        | 77.7M/380M [00:02<00:07, 42.6MB/s]     22%|##1       | 83.6M/380M [00:02<00:07, 42.8MB/s]     24%|##3       | 89.4M/380M [00:02<00:07, 42.9MB/s]     25%|##5       | 95.2M/380M [00:02<00:06, 43.0MB/s]     27%|##6       | 101M/380M [00:02<00:06, 43.1MB/s]      28%|##7       | 106M/380M [00:03<00:06, 41.7MB/s]     29%|##9       | 112M/380M [00:03<00:06, 42.0MB/s]     31%|###       | 118M/380M [00:03<00:06, 42.0MB/s]     32%|###2      | 123M/380M [00:03<00:06, 41.8MB/s]     34%|###3      | 129M/380M [00:03<00:06, 42.0MB/s]     35%|###5      | 135M/380M [00:03<00:06, 42.6MB/s]     37%|###7      | 141M/380M [00:03<00:05, 42.9MB/s]     38%|###8      | 146M/380M [00:04<00:05, 42.6MB/s]     40%|####      | 152M/380M [00:04<00:05, 42.7MB/s]     42%|####1     | 158M/380M [00:04<00:05, 42.9MB/s]     43%|####3     | 164M/380M [00:04<00:05, 42.9MB/s]     45%|####4     | 169M/380M [00:04<00:05, 42.7MB/s]     46%|####6     | 175M/380M [00:04<00:05, 42.9MB/s]     48%|####7     | 181M/380M [00:04<00:04, 42.9MB/s]     49%|####9     | 187M/380M [00:05<00:04, 42.7MB/s]     51%|#####     | 192M/380M [00:05<00:04, 42.8MB/s]     52%|#####2    | 198M/380M [00:05<00:04, 42.8MB/s]     54%|#####3    | 204M/380M [00:05<00:04, 43.1MB/s]     55%|#####5    | 210M/380M [00:05<00:04, 43.1MB/s]     57%|#####6    | 216M/380M [00:05<00:03, 43.2MB/s]     58%|#####8    | 221M/380M [00:05<00:03, 43.0MB/s]     60%|#####9    | 227M/380M [00:06<00:03, 42.5MB/s]     61%|######1   | 233M/380M [00:06<00:03, 42.6MB/s]     63%|######2   | 238M/380M [00:06<00:03, 42.6MB/s]     64%|######4   | 244M/380M [00:06<00:03, 42.8MB/s]     66%|######5   | 250M/380M [00:06<00:03, 42.8MB/s]     67%|######7   | 256M/380M [00:06<00:03, 42.8MB/s]     69%|######8   | 261M/380M [00:06<00:02, 42.8MB/s]     70%|#######   | 267M/380M [00:07<00:02, 42.9MB/s]     71%|#######1  | 272M/380M [00:07<00:02, 38.6MB/s]     73%|#######2  | 276M/380M [00:07<00:02, 37.5MB/s]     74%|#######4  | 282M/380M [00:07<00:02, 38.2MB/s]     76%|#######5  | 287M/380M [00:07<00:02, 39.3MB/s]     77%|#######7  | 293M/380M [00:07<00:02, 39.9MB/s]     79%|#######8  | 299M/380M [00:07<00:02, 40.7MB/s]     80%|########  | 304M/380M [00:08<00:01, 42.0MB/s]     81%|########1 | 309M/380M [00:08<00:01, 44.9MB/s]     82%|########2 | 313M/380M [00:08<00:01, 41.5MB/s]     84%|########3 | 318M/380M [00:08<00:01, 45.1MB/s]     85%|########4 | 322M/380M [00:08<00:01, 41.1MB/s]     86%|########5 | 327M/380M [00:08<00:01, 44.1MB/s]     87%|########6 | 330M/380M [00:08<00:01, 40.9MB/s]     88%|########8 | 335M/380M [00:08<00:01, 44.1MB/s]     89%|########9 | 339M/380M [00:08<00:01, 40.5MB/s]     91%|######### | 344M/380M [00:08<00:00, 44.6MB/s]     91%|#########1| 347M/380M [00:09<00:00, 40.6MB/s]     93%|#########2| 352M/380M [00:09<00:00, 45.0MB/s]     94%|#########3| 356M/380M [00:09<00:00, 40.9MB/s]     95%|#########5| 361M/380M [00:09<00:00, 44.7MB/s]     96%|#########5| 365M/380M [00:09<00:00, 41.1MB/s]     97%|#########7| 370M/380M [00:09<00:00, 45.1MB/s]     98%|#########8| 373M/380M [00:09<00:00, 41.1MB/s]    100%|#########9| 379M/380M [00:09<00:00, 45.2MB/s]    100%|##########| 380M/380M [00:09<00:00, 40.3MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 23-27

Representation image in container:
The image(s) are in the :attr:`img.data` attribute of the instance, which is an
:class:`xarray.Dataset`. Note that this is a Dataset so that this attribute can hold
multiple image-structured layers.

.. GENERATED FROM PYTHON SOURCE LINES 27-29

.. code-block:: default

    print(img.data)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <xarray.Dataset>
    Dimensions:  (channels: 3, x: 11291, y: 11757)
    Dimensions without coordinates: channels, x, y
    Data variables:
        image    (y, x, channels) uint8 129 134 127 129 132 ... 133 131 131 131 128
    Attributes:
        coords:       CropCoords(x0=0, y0=0, x1=0, y1=0)
        padding:      CropPadding(x_pre=0, y_pre=0, x_post=0, y_post=0)
        scale:        1
        mask_circle:  False




.. GENERATED FROM PYTHON SOURCE LINES 30-32

You can access specific image-structured arrays in the image using their
names.

.. GENERATED FROM PYTHON SOURCE LINES 32-34

.. code-block:: default

    print(img["image"])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    <xarray.DataArray 'image' (y: 11757, x: 11291, channels: 3)>
    array([[[129, 134, 127],
            [129, 132, 127],
            [129, 132, 127],
            ...,
            [127, 129, 123],
            [128, 129, 125],
            [128, 130, 126]],

           [[130, 134, 127],
            [131, 135, 128],
            [130, 132, 128],
            ...,
            [128, 130, 125],
            [128, 130, 126],
            [128, 129, 124]],

           [[128, 136, 128],
            [129, 135, 128],
            [127, 132, 126],
            ...,
    ...
            ...,
            [131, 133, 129],
            [131, 132, 128],
            [128, 129, 125]],

           [[130, 132, 127],
            [131, 132, 128],
            [131, 132, 126],
            ...,
            [132, 134, 133],
            [132, 132, 130],
            [129, 130, 127]],

           [[130, 132, 127],
            [132, 133, 127],
            [132, 133, 127],
            ...,
            [133, 135, 133],
            [133, 133, 131],
            [131, 131, 128]]], dtype=uint8)
    Dimensions without coordinates: y, x, channels
    Attributes:
        transform:               (1.0, 0.0, 0.0, 0.0, 1.0, 0.0)
        res:                     (1.0, -1.0)
        is_tiled:                0
        nodatavals:              (nan, nan, nan)
        scales:                  (1.0, 1.0, 1.0)
        offsets:                 (0.0, 0.0, 0.0)
        TIFFTAG_MAXSAMPLEVALUE:  255




.. GENERATED FROM PYTHON SOURCE LINES 35-38

Lazy loading:
The image data can be lazily loaded with `netcdf` and explicitly loaded into
memory via ``.data.load()`` and saved to disk via ``.save()``:

.. GENERATED FROM PYTHON SOURCE LINES 38-40

.. code-block:: default

    img.data.load()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div><svg style="position: absolute; width: 0; height: 0; overflow: hidden">
    <defs>
    <symbol id="icon-database" viewBox="0 0 32 32">
    <path d="M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z"></path>
    <path d="M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
    <path d="M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z"></path>
    </symbol>
    <symbol id="icon-file-text2" viewBox="0 0 32 32">
    <path d="M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z"></path>
    <path d="M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
    <path d="M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
    <path d="M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z"></path>
    </symbol>
    </defs>
    </svg>
    <style>/* CSS stylesheet for displaying xarray objects in jupyterlab.
     *
     */

    :root {
      --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));
      --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));
      --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));
      --xr-border-color: var(--jp-border-color2, #e0e0e0);
      --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);
      --xr-background-color: var(--jp-layout-color0, white);
      --xr-background-color-row-even: var(--jp-layout-color1, white);
      --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);
    }

    html[theme=dark],
    body.vscode-dark {
      --xr-font-color0: rgba(255, 255, 255, 1);
      --xr-font-color2: rgba(255, 255, 255, 0.54);
      --xr-font-color3: rgba(255, 255, 255, 0.38);
      --xr-border-color: #1F1F1F;
      --xr-disabled-color: #515151;
      --xr-background-color: #111111;
      --xr-background-color-row-even: #111111;
      --xr-background-color-row-odd: #313131;
    }

    .xr-wrap {
      display: block;
      min-width: 300px;
      max-width: 700px;
    }

    .xr-text-repr-fallback {
      /* fallback to plain text repr when CSS is not injected (untrusted notebook) */
      display: none;
    }

    .xr-header {
      padding-top: 6px;
      padding-bottom: 6px;
      margin-bottom: 4px;
      border-bottom: solid 1px var(--xr-border-color);
    }

    .xr-header > div,
    .xr-header > ul {
      display: inline;
      margin-top: 0;
      margin-bottom: 0;
    }

    .xr-obj-type,
    .xr-array-name {
      margin-left: 2px;
      margin-right: 10px;
    }

    .xr-obj-type {
      color: var(--xr-font-color2);
    }

    .xr-sections {
      padding-left: 0 !important;
      display: grid;
      grid-template-columns: 150px auto auto 1fr 20px 20px;
    }

    .xr-section-item {
      display: contents;
    }

    .xr-section-item input {
      display: none;
    }

    .xr-section-item input + label {
      color: var(--xr-disabled-color);
    }

    .xr-section-item input:enabled + label {
      cursor: pointer;
      color: var(--xr-font-color2);
    }

    .xr-section-item input:enabled + label:hover {
      color: var(--xr-font-color0);
    }

    .xr-section-summary {
      grid-column: 1;
      color: var(--xr-font-color2);
      font-weight: 500;
    }

    .xr-section-summary > span {
      display: inline-block;
      padding-left: 0.5em;
    }

    .xr-section-summary-in:disabled + label {
      color: var(--xr-font-color2);
    }

    .xr-section-summary-in + label:before {
      display: inline-block;
      content: '►';
      font-size: 11px;
      width: 15px;
      text-align: center;
    }

    .xr-section-summary-in:disabled + label:before {
      color: var(--xr-disabled-color);
    }

    .xr-section-summary-in:checked + label:before {
      content: '▼';
    }

    .xr-section-summary-in:checked + label > span {
      display: none;
    }

    .xr-section-summary,
    .xr-section-inline-details {
      padding-top: 4px;
      padding-bottom: 4px;
    }

    .xr-section-inline-details {
      grid-column: 2 / -1;
    }

    .xr-section-details {
      display: none;
      grid-column: 1 / -1;
      margin-bottom: 5px;
    }

    .xr-section-summary-in:checked ~ .xr-section-details {
      display: contents;
    }

    .xr-array-wrap {
      grid-column: 1 / -1;
      display: grid;
      grid-template-columns: 20px auto;
    }

    .xr-array-wrap > label {
      grid-column: 1;
      vertical-align: top;
    }

    .xr-preview {
      color: var(--xr-font-color3);
    }

    .xr-array-preview,
    .xr-array-data {
      padding: 0 5px !important;
      grid-column: 2;
    }

    .xr-array-data,
    .xr-array-in:checked ~ .xr-array-preview {
      display: none;
    }

    .xr-array-in:checked ~ .xr-array-data,
    .xr-array-preview {
      display: inline-block;
    }

    .xr-dim-list {
      display: inline-block !important;
      list-style: none;
      padding: 0 !important;
      margin: 0;
    }

    .xr-dim-list li {
      display: inline-block;
      padding: 0;
      margin: 0;
    }

    .xr-dim-list:before {
      content: '(';
    }

    .xr-dim-list:after {
      content: ')';
    }

    .xr-dim-list li:not(:last-child):after {
      content: ',';
      padding-right: 5px;
    }

    .xr-has-index {
      font-weight: bold;
    }

    .xr-var-list,
    .xr-var-item {
      display: contents;
    }

    .xr-var-item > div,
    .xr-var-item label,
    .xr-var-item > .xr-var-name span {
      background-color: var(--xr-background-color-row-even);
      margin-bottom: 0;
    }

    .xr-var-item > .xr-var-name:hover span {
      padding-right: 5px;
    }

    .xr-var-list > li:nth-child(odd) > div,
    .xr-var-list > li:nth-child(odd) > label,
    .xr-var-list > li:nth-child(odd) > .xr-var-name span {
      background-color: var(--xr-background-color-row-odd);
    }

    .xr-var-name {
      grid-column: 1;
    }

    .xr-var-dims {
      grid-column: 2;
    }

    .xr-var-dtype {
      grid-column: 3;
      text-align: right;
      color: var(--xr-font-color2);
    }

    .xr-var-preview {
      grid-column: 4;
    }

    .xr-var-name,
    .xr-var-dims,
    .xr-var-dtype,
    .xr-preview,
    .xr-attrs dt {
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
      padding-right: 10px;
    }

    .xr-var-name:hover,
    .xr-var-dims:hover,
    .xr-var-dtype:hover,
    .xr-attrs dt:hover {
      overflow: visible;
      width: auto;
      z-index: 1;
    }

    .xr-var-attrs,
    .xr-var-data {
      display: none;
      background-color: var(--xr-background-color) !important;
      padding-bottom: 5px !important;
    }

    .xr-var-attrs-in:checked ~ .xr-var-attrs,
    .xr-var-data-in:checked ~ .xr-var-data {
      display: block;
    }

    .xr-var-data > table {
      float: right;
    }

    .xr-var-name span,
    .xr-var-data,
    .xr-attrs {
      padding-left: 25px !important;
    }

    .xr-attrs,
    .xr-var-attrs,
    .xr-var-data {
      grid-column: 1 / -1;
    }

    dl.xr-attrs {
      padding: 0;
      margin: 0;
      display: grid;
      grid-template-columns: 125px auto;
    }

    .xr-attrs dt,
    .xr-attrs dd {
      padding: 0;
      margin: 0;
      float: left;
      padding-right: 10px;
      width: auto;
    }

    .xr-attrs dt {
      font-weight: normal;
      grid-column: 1;
    }

    .xr-attrs dt:hover span {
      display: inline-block;
      background: var(--xr-background-color);
      padding-right: 10px;
    }

    .xr-attrs dd {
      grid-column: 2;
      white-space: pre-wrap;
      word-break: break-all;
    }

    .xr-icon-database,
    .xr-icon-file-text2 {
      display: inline-block;
      vertical-align: middle;
      width: 1em;
      height: 1.5em !important;
      stroke-width: 0;
      stroke: currentColor;
      fill: currentColor;
    }
    </style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;
    Dimensions:  (channels: 3, x: 11291, y: 11757)
    Dimensions without coordinates: channels, x, y
    Data variables:
        image    (y, x, channels) uint8 129 134 127 129 132 ... 133 131 131 131 128
    Attributes:
        coords:       CropCoords(x0=0, y0=0, x1=0, y1=0)
        padding:      CropPadding(x_pre=0, y_pre=0, x_post=0, y_post=0)
        scale:        1
        mask_circle:  False</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-971fbeb3-37af-4f34-82b9-dc8638049da0' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-971fbeb3-37af-4f34-82b9-dc8638049da0' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span>channels</span>: 3</li><li><span>x</span>: 11291</li><li><span>y</span>: 11757</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-d92911ee-b6df-42e3-84ab-fb07ee9a8639' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-d92911ee-b6df-42e3-84ab-fb07ee9a8639' class='xr-section-summary'  title='Expand/collapse section'>Coordinates: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-7293ac08-4e3c-4168-b8fd-3e0e67d68af6' class='xr-section-summary-in' type='checkbox'  checked><label for='section-7293ac08-4e3c-4168-b8fd-3e0e67d68af6' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>image</span></div><div class='xr-var-dims'>(y, x, channels)</div><div class='xr-var-dtype'>uint8</div><div class='xr-var-preview xr-preview'>129 134 127 129 ... 131 131 131 128</div><input id='attrs-f60d9ad5-c3ad-41ce-a257-ff2604e7cfef' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-f60d9ad5-c3ad-41ce-a257-ff2604e7cfef' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9c2483b7-0d2b-4c69-8333-70cfc8c7295f' class='xr-var-data-in' type='checkbox'><label for='data-9c2483b7-0d2b-4c69-8333-70cfc8c7295f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>transform :</span></dt><dd>(1.0, 0.0, 0.0, 0.0, 1.0, 0.0)</dd><dt><span>res :</span></dt><dd>(1.0, -1.0)</dd><dt><span>is_tiled :</span></dt><dd>0</dd><dt><span>nodatavals :</span></dt><dd>(nan, nan, nan)</dd><dt><span>scales :</span></dt><dd>(1.0, 1.0, 1.0)</dd><dt><span>offsets :</span></dt><dd>(0.0, 0.0, 0.0)</dd><dt><span>TIFFTAG_MAXSAMPLEVALUE :</span></dt><dd>255</dd></dl></div><div class='xr-var-data'><pre>array([[[129, 134, 127],
            [129, 132, 127],
            [129, 132, 127],
            ...,
            [127, 129, 123],
            [128, 129, 125],
            [128, 130, 126]],

           [[130, 134, 127],
            [131, 135, 128],
            [130, 132, 128],
            ...,
            [128, 130, 125],
            [128, 130, 126],
            [128, 129, 124]],

           [[128, 136, 128],
            [129, 135, 128],
            [127, 132, 126],
            ...,
    ...
            ...,
            [131, 133, 129],
            [131, 132, 128],
            [128, 129, 125]],

           [[130, 132, 127],
            [131, 132, 128],
            [131, 132, 126],
            ...,
            [132, 134, 133],
            [132, 132, 130],
            [129, 130, 127]],

           [[130, 132, 127],
            [132, 133, 127],
            [132, 133, 127],
            ...,
            [133, 135, 133],
            [133, 133, 131],
            [131, 131, 128]]], dtype=uint8)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-97fdcf87-425e-41b3-9ab8-404dcc77ac1e' class='xr-section-summary-in' type='checkbox'  checked><label for='section-97fdcf87-425e-41b3-9ab8-404dcc77ac1e' class='xr-section-summary' >Attributes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>coords :</span></dt><dd>CropCoords(x0=0, y0=0, x1=0, y1=0)</dd><dt><span>padding :</span></dt><dd>CropPadding(x_pre=0, y_pre=0, x_post=0, y_post=0)</dd><dt><span>scale :</span></dt><dd>1</dd><dt><span>mask_circle :</span></dt><dd>False</dd></dl></div></li></ul></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 41-47

You can add images into the ImageContainer using ``.add_img()``:
Here we are adding the same image again under a different name as a toy example.
It shares the same channel dimension with "image", so we can use the same
label for ``channel_dim`` here.
If the added image layer has a different channel dimension, just specify a new
label for ``channel_dim``.

.. GENERATED FROM PYTHON SOURCE LINES 47-54

.. code-block:: default

    img.add_img(
        img=img.data["image"],
        layer="image2",
        channel_dim="channels",
        lazy=True,
    )
    img





.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    ImageContainer object with 2 layers:<p style='text-indent: 25px; margin-top: 0px;'><strong>image</strong>: <em>y</em> (11757), <em>x</em> (11291), <em>channels</em> (3)</p><p style='text-indent: 25px; margin-top: 0px;'><strong>image2</strong>: <em>y</em> (11757), <em>x</em> (11291), <em>channels</em> (3)</p>
    </div>
    <br />
    <br />


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  12.864 seconds)

**Estimated memory usage:**  862 MB


.. _sphx_glr_download_auto_examples_image_compute_image_container.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: compute_image_container.py <compute_image_container.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: compute_image_container.ipynb <compute_image_container.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
