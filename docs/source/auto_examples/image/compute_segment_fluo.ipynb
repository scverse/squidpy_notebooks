{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell-segmentation for fluorescence images\n\nThis example shows how to use the high resolution tissue images to\nsegment nuclei.\n\nThis information can be used to compute additional image features like\ncell count and cell size per spot (see\n`sphx_glr_auto_examples_image_compute_segmentation_features.py`). This\nexample shows how to use `squidpy.im.segment` and explains the\nparameters you can use.\n\nWe provide a built-in segmentation model\n`squidpy.im.SegmentationWatershed`. In addition, you can use a custom\nsegmentation function, like a pre-trained `tensorflow.keras` model, to\nperform the segmentation utilizing `squidpy.im.SegmentationCustom`.\n\nNote that when using the provided segmentation model\n[\\'watershed\\']{.title-ref}, the quality of the cell-segmentation\ndepends on the quality of your tissue images. In this example we use the\nDAPI stain of a fluorescence dataset to compute the segmentation. For\nharder cases, you may want to provide your own pre-trained segmentation\nmodel.\n\n::: seealso\n-   `sphx_glr_auto_examples_image_compute_segment_hne.py` for an example\n    on how to calculate a cell-segmentation of an H&E stain.\n-   [Nuclei Segmentation using\n    Cellpose](../../external_tutorials/tutorial_cellpose_segmentation.ipynb)\n    for a tutorial on using Cellpose as a custom segmentation function.\n-   [Nuclei Segmentation using\n    StarDist](../../external_tutorials/tutorial_stardist.ipynb) for a\n    tutorial on using StarDist as a custom segmentation function.\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import squidpy as sq\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n# load fluorescence tissue image\nimg = sq.datasets.visium_fluo_image_crop()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We crop the image to a smaller segment. This is only to speed things up,\n`squidpy.im.segment` can also process very large images (see\n`sphx_glr_auto_examples_image_compute_process_hires.py`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "crop = img.crop_corner(1000, 1000, size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The tissue image in this dataset contains four fluorescence stains. The\nfirst one is DAPI, which we will use for the nuclei-segmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "crop.show(\"image\", channelwise=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We segment the image with `squidpy.im.segment` using watershed\nsegmentation (`method = 'watershed'`). With the arguments `layer` and\n`channel` we define the image layer and channel of the image that should\nbe segmented.\n\nWith `kwargs` we can provide keyword arguments to the segmentation\nmodel. For watershed segmentation, we need to set a threshold to create\nthe mask image. You can either set a manual threshold, or use automated\n[Otsu thresholding](https://en.wikipedia.org/wiki/Otsu%27s_method). For\nthis fluorescence image example, Otsu\\'s thresh works very well, thus we\nwill use `thresh = None`. See\n`sphx_glr_auto_examples_image_compute_segment_hne.py` for an example\nwhere we use a manually defined threshold.\n\nIn addition, we can specify if the values greater or equal than the\nthreshold should be in the mask (default) or if the values smaller to\nthe threshold should be in the mask (`geq = False`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sq.im.segment(img=crop, layer=\"image\", channel=0, method=\"watershed\", thresh=None, geq=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The segmented crop is saved in the layer `segmented_watershed`. This\nbehavior can be changed with the arguments `copy` and `layer_added`. The\nresult of the segmentation is a label image that can be used to extract\nfeatures like the number of cells from the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(crop)\nprint(f\"Number of segments in crop: {len(np.unique(crop['segmented_watershed']))}\")\n\nfig, axes = plt.subplots(1, 2)\ncrop.show(\"image\", channel=0, ax=axes[0])\n_ = axes[0].set_title(\"DAPI\")\ncrop.show(\"segmented_watershed\", cmap=\"jet\", interpolation=\"none\", ax=axes[1])\n_ = axes[1].set_title(\"segmentation\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}